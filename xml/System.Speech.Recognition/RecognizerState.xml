<Type Name="RecognizerState" FullName="System.Speech.Recognition.RecognizerState">
  <Metadata>
    <Meta Name="ms.openlocfilehash" Value="f5b640ed1cb602559a7f842753c580aa066c67e8" />
    <Meta Name="ms.sourcegitcommit" Value="5a49536d99d2d0b54e4cb7280870903e043272df" />
    <Meta Name="ms.translationtype" Value="HT" />
    <Meta Name="ms.contentlocale" Value="es-ES" />
    <Meta Name="ms.lasthandoff" Value="07/03/2018" />
    <Meta Name="ms.locfileid" Value="37756182" />
  </Metadata>
  <TypeSignature Language="C#" Value="public enum RecognizerState" />
  <TypeSignature Language="ILAsm" Value=".class public auto ansi sealed RecognizerState extends System.Enum" />
  <TypeSignature Language="DocId" Value="T:System.Speech.Recognition.RecognizerState" />
  <TypeSignature Language="VB.NET" Value="Public Enum RecognizerState" />
  <TypeSignature Language="C++ CLI" Value="public enum class RecognizerState" />
  <TypeSignature Language="F#" Value="type RecognizerState = " />
  <AssemblyInfo>
    <AssemblyName>System.Speech</AssemblyName>
    <AssemblyVersion>3.0.0.0</AssemblyVersion>
    <AssemblyVersion>4.0.0.0</AssemblyVersion>
  </AssemblyInfo>
  <Base>
    <BaseTypeName>System.Enum</BaseTypeName>
  </Base>
  <Docs>
    <summary>Enumera los valores del estado del reconocedor.</summary>
    <remarks>
      <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <xref:System.Speech.Recognition.RecognizerState> encapsula el estado de ejecución del motor de reconocimiento de voz predeterminado para los clientes que usan <xref:System.Speech.Recognition.SpeechRecognizer> para acceder al servicio de la tecnología de reconocimiento de voz de escritorio de Windows.  
  
 Las aplicaciones pueden obtener el estado actual del motor de reconocimiento de escritorio como un <xref:System.Speech.Recognition.RecognizerState> objeto consultando la <xref:System.Speech.Recognition.SpeechRecognizer.State%2A> propiedad en un <xref:System.Speech.Recognition.SpeechRecognizer> instancia.  Para obtener el estado del motor de reconocimiento de escritorio después del cambio, las aplicaciones pueden consultar el <xref:System.Speech.Recognition.StateChangedEventArgs.RecognizerState%2A> propiedad de la <xref:System.Speech.Recognition.StateChangedEventArgs> objeto pasa a un controlador para <xref:System.Speech.Recognition.SpeechRecognizer.StateChanged> eventos.  
  
> [!NOTE]
>  <xref:System.Speech.Recognition.SpeechRecognitionEngine> las instancias se ejecutan en proceso y su estado de ejecución está bajo el control de la aplicación. Por lo tanto, <xref:System.Speech.Recognition.SpeechRecognitionEngine> no contiene una propiedad para devolver un <xref:System.Speech.Recognition.RecognizerState> objeto.  
  
 El estado de un servidor de reconocimiento de voz de escritorio es una propiedad de solo lectura y no se puede controlar mediante programación. Los usuarios pueden cambiar el estado de un reconocedor voz compartido mediante la interfaz de usuario (UI) de reconocimiento de voz o a través del **el reconocimiento de voz** miembro de la Windows **Panel de Control**.  
  
 Tanto el **en** y **suspensión** configuración en la interfaz de usuario de reconocimiento de voz se corresponde con el `Listening` estado. El **desactivar** configuración de la interfaz de usuario de reconocimiento de voz corresponde a detenido.  
  
 <xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A> es la otra propiedad que afecta a la preparación de un motor de reconocimiento de voz compartido para recibir y procesar la entrada de voz. Puede usar <xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A> para controlar o no están activas para el reconocimiento de las gramáticas del motor de reconocimiento de voz compartido. Sin embargo, cambiar el <xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A> propiedad no tiene ningún efecto sobre el <xref:System.Speech.Recognition.RecognizerState> propiedad.  
  
 Información como la descripción, la referencia cultural compatible y formatos de audio y el nombre del motor de reconocimiento se encapsula en la <xref:System.Speech.Recognition.RecognizerInfo> tipo.  
  
   
  
## Examples  
 En el ejemplo siguiente, una aplicación muestra el estado de un módulo de reconocimiento en su implementación de un controlador para el <xref:System.Speech.Recognition.SpeechRecognizer.StateChanged> eventos.  
  
```  
  
_recognizer.StateChanged +=  
    delegate(object sender, StateChangedEventArgs eventArgs) {  
        _recognizerStateLabel.Text = "Speech Recognizer State: " + eventArgs.RecognizerState.ToString();  
    };  
  
```  
  
 ]]></format>
    </remarks>
    <altmember cref="P:System.Speech.Recognition.StateChangedEventArgs.RecognizerState" />
    <altmember cref="T:System.Speech.Recognition.SpeechRecognizer" />
    <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.Enabled" />
    <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.State" />
    <altmember cref="T:System.Speech.Recognition.StateChangedEventArgs" />
    <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.StateChanged" />
  </Docs>
  <Members>
    <Member MemberName="Listening">
      <MemberSignature Language="C#" Value="Listening" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype System.Speech.Recognition.RecognizerState Listening = int32(1)" />
      <MemberSignature Language="DocId" Value="F:System.Speech.Recognition.RecognizerState.Listening" />
      <MemberSignature Language="VB.NET" Value="Listening" />
      <MemberSignature Language="C++ CLI" Value="Listening" />
      <MemberSignature Language="F#" Value="Listening = 1" Usage="System.Speech.Recognition.RecognizerState.Listening" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Recognition.RecognizerState</ReturnType>
      </ReturnValue>
      <MemberValue>1</MemberValue>
      <Docs>
        <summary>El motor de reconocimiento está disponible para recibir y analizar la entrada de audio.</summary>
      </Docs>
    </Member>
    <Member MemberName="Stopped">
      <MemberSignature Language="C#" Value="Stopped" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype System.Speech.Recognition.RecognizerState Stopped = int32(0)" />
      <MemberSignature Language="DocId" Value="F:System.Speech.Recognition.RecognizerState.Stopped" />
      <MemberSignature Language="VB.NET" Value="Stopped" />
      <MemberSignature Language="C++ CLI" Value="Stopped" />
      <MemberSignature Language="F#" Value="Stopped = 0" Usage="System.Speech.Recognition.RecognizerState.Stopped" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Recognition.RecognizerState</ReturnType>
      </ReturnValue>
      <MemberValue>0</MemberValue>
      <Docs>
        <summary>El motor de reconocimiento no está recibiendo o analizando la entrada de audio.</summary>
      </Docs>
    </Member>
  </Members>
</Type>