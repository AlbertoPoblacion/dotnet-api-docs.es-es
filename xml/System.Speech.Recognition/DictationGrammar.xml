<Type Name="DictationGrammar" FullName="System.Speech.Recognition.DictationGrammar">
  <Metadata>
    <Meta Name="ms.openlocfilehash" Value="03cbcbf150eedd38688c32681c06070f0170c03d" />
    <Meta Name="ms.sourcegitcommit" Value="d31dc2ede16f6f7bc64e90d9f897ff54c4e3869b" />
    <Meta Name="ms.translationtype" Value="HT" />
    <Meta Name="ms.contentlocale" Value="es-ES" />
    <Meta Name="ms.lasthandoff" Value="04/03/2018" />
    <Meta Name="ms.locfileid" Value="30526409" />
  </Metadata>
  <TypeSignature Language="C#" Value="public class DictationGrammar : System.Speech.Recognition.Grammar" />
  <TypeSignature Language="ILAsm" Value=".class public auto ansi beforefieldinit DictationGrammar extends System.Speech.Recognition.Grammar" />
  <TypeSignature Language="DocId" Value="T:System.Speech.Recognition.DictationGrammar" />
  <TypeSignature Language="VB.NET" Value="Public Class DictationGrammar&#xA;Inherits Grammar" />
  <TypeSignature Language="C++ CLI" Value="public ref class DictationGrammar : System::Speech::Recognition::Grammar" />
  <AssemblyInfo>
    <AssemblyName>System.Speech</AssemblyName>
    <AssemblyVersion>4.0.0.0</AssemblyVersion>
  </AssemblyInfo>
  <Base>
    <BaseTypeName>System.Speech.Recognition.Grammar</BaseTypeName>
  </Base>
  <Interfaces />
  <Docs>
    <summary>Representa una gramática de reconocimiento de voz usada para el dictado de texto libre.</summary>
    <remarks>
      <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Esta clase proporciona aplicaciones con un modelo de lenguaje predefinido que puede procesar proporcionados por el usuario hablado en texto. Esta clase admite predeterminados y personalizados <xref:System.Speech.Recognition.DictationGrammar> objetos. Para obtener información acerca de cómo seleccionar una gramática dictado, consulte el <xref:System.Speech.Recognition.DictationGrammar.%23ctor%28System.String%29> constructor.  
  
 De forma predeterminada, el <xref:System.Speech.Recognition.DictationGrammar> un modelo de idioma es libre de contexto. No hace uso de palabras específicas o la palabra de orden para identificar e interpretar la entrada de audio. Para agregar contexto de la gramática de dictado, use la <xref:System.Speech.Recognition.DictationGrammar.SetDictationContext%2A> método.  
  
> [!NOTE]
>  <xref:System.Speech.Recognition.DictationGrammar> los objetos no admiten la <xref:System.Speech.Recognition.Grammar.Priority%2A> propiedad. <xref:System.Speech.Recognition.DictationGrammar> produce una <xref:System.NotSupportedException> si <xref:System.Speech.Recognition.Grammar.Priority%2A> se establece.  
  
   
  
## Examples  
 El siguiente ejemplo crea tres de las gramáticas de dictado, agrega a un nuevo <xref:System.Speech.Recognition.SpeechRecognitionEngine> de objetos y devuelve el objeto nuevo. La gramática de la primera es la gramática de dictado de forma predeterminada. La gramática de la segunda es la ortografía y gramática dictado. La gramática de la tercera es la gramática de dictado predeterminado que incluye una frase de contexto. El <xref:System.Speech.Recognition.DictationGrammar.SetDictationContext%2A> método se utiliza para asociar la frase de contexto con la gramática de dictado después de que se cargue en el <xref:System.Speech.Recognition.SpeechRecognitionEngine> objeto.  
  
```csharp  
  
private SpeechRecognitionEngine LoadDictationGrammars()  
{  
  
  // Create a default dictation grammar.  
  DictationGrammar defaultDictationGrammar = new DictationGrammar();  
  defaultDictationGrammar.Name = "default dictation";  
  defaultDictationGrammar.Enabled = true;  
  
  // Create the spelling dictation grammar.  
  DictationGrammar spellingDictationGrammar =  
    new DictationGrammar("grammar:dictation#spelling");  
  spellingDictationGrammar.Name = "spelling dictation";  
  spellingDictationGrammar.Enabled = true;  
  
  // Create the question dictation grammar.  
  DictationGrammar customDictationGrammar =  
    new DictationGrammar("grammar:dictation");  
  customDictationGrammar.Name = "question dictation";  
  customDictationGrammar.Enabled = true;  
  
  // Create a SpeechRecognitionEngine object and add the grammars to it.  
  SpeechRecognitionEngine recoEngine = new SpeechRecognitionEngine();  
  recoEngine.LoadGrammar(defaultDictationGrammar);  
  recoEngine.LoadGrammar(spellingDictationGrammar);  
  recoEngine.LoadGrammar(customDictationGrammar);  
  
  // Add a context to customDictationGrammar.  
  customDictationGrammar.SetDictationContext("How do you", null);  
  
  return recoEngine;  
}  
  
```  
  
 ]]></format>
    </remarks>
    <altmember cref="T:System.Speech.Recognition.Grammar" />
  </Docs>
  <Members>
    <MemberGroup MemberName=".ctor">
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Docs>
        <summary>Inicializa una nueva instancia de la clase <see cref="T:System.Speech.Recognition.DictationGrammar" />.</summary>
      </Docs>
    </MemberGroup>
    <Member MemberName=".ctor">
      <MemberSignature Language="C#" Value="public DictationGrammar ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig specialname rtspecialname instance void .ctor() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.DictationGrammar.#ctor" />
      <MemberSignature Language="VB.NET" Value="Public Sub New ()" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; DictationGrammar();" />
      <MemberType>Constructor</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Parameters />
      <Docs>
        <summary>Inicializa una nueva instancia de la clase <see cref="T:System.Speech.Recognition.DictationGrammar" /> para la gramática de dictado predeterminada proporcionada por la tecnología Windows Desktop Speech.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 La gramática de dictado predeterminado emula prácticas de dictado estándar, incluidos los signos de puntuación. No se admite la ortografía de una palabra.  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName=".ctor">
      <MemberSignature Language="C#" Value="public DictationGrammar (string topic);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig specialname rtspecialname instance void .ctor(string topic) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.DictationGrammar.#ctor(System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Sub New (topic As String)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; DictationGrammar(System::String ^ topic);" />
      <MemberType>Constructor</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Parameters>
        <Parameter Name="topic" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="topic">Identificador de recursos universal (URI) conforme a XML que especifica la gramática de dictado, ya sea <c>grammar:dictation</c> o <c>grammar:dictation#spelling</c>.</param>
        <summary>Inicializa una nueva instancia de la clase <see cref="T:System.Speech.Recognition.DictationGrammar" /> con una gramática de dictado específica.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 La plataforma de voz utiliza una sintaxis URI especializada para definir la gramática de dictado personalizado. El valor `grammar:dictation` indica la gramática de dictado de forma predeterminada. El valor `grammar:dictation#spelling` indica la ortografía y gramática dictado.  
  
 ]]></format>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="SetDictationContext">
      <MemberSignature Language="C#" Value="public void SetDictationContext (string precedingText, string subsequentText);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void SetDictationContext(string precedingText, string subsequentText) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.DictationGrammar.SetDictationContext(System.String,System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Sub SetDictationContext (precedingText As String, subsequentText As String)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void SetDictationContext(System::String ^ precedingText, System::String ^ subsequentText);" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="precedingText" Type="System.String" />
        <Parameter Name="subsequentText" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="precedingText">Texto que indica el principio de un contexto de dictado.</param>
        <param name="subsequentText">Texto que indica el final de un contexto de dictado.</param>
        <summary>Agrega un contexto a una gramática de dictado que un objeto <see cref="T:System.Speech.Recognition.SpeechRecognizer" /> o <see cref="T:System.Speech.Recognition.SpeechRecognitionEngine" /> ha cargado.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 De forma predeterminada, la gramática de dictado no hace que el uso de palabras específicas o la palabra de orden para identificar e interpretar la entrada de audio. Cuando un contexto se agrega a una gramática dictado, el motor de reconocimiento usa el `precedingText` y `subsequentText` para identificar cuándo se debe interpretar voz como dictado.  
  
> [!NOTE]
>  Debe cargarse una gramática dictado por un <xref:System.Speech.Recognition.SpeechRecognizer> o <xref:System.Speech.Recognition.SpeechRecognitionEngine> objeto antes de poder usar <xref:System.Speech.Recognition.DictationGrammar.SetDictationContext%2A> para agregar un contexto.  
  
 En la tabla siguiente describe cómo el motor de reconocimiento utiliza los dos parámetros para determinar cuándo se debe usar la gramática de dictado.  
  
|`precedingText`|`subsequentText`|Descripción|  
|---------------------|----------------------|-----------------|  
|no `null`|no `null`|El motor de reconocimiento utiliza los términos para catalogar frases candidatas posibles.|  
|`null`|no `null`|Utiliza el motor de reconocimiento de la `subsequentText` a que finalice el dictado.|  
|no `null`|`null`|Utiliza el motor de reconocimiento de la `precedingText` para iniciar el dictado.|  
|`null`|`null`|El motor de reconocimiento no utilizan un contexto cuando se utiliza la gramática de dictado.|  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.Grammar" />
      </Docs>
    </Member>
  </Members>
</Type>