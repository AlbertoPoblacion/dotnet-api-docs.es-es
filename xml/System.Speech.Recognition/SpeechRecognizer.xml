<Type Name="SpeechRecognizer" FullName="System.Speech.Recognition.SpeechRecognizer">
  <Metadata>
    <Meta Name="ms.openlocfilehash" Value="8207c8323b581f34284814159f646971bbb28349" />
    <Meta Name="ms.sourcegitcommit" Value="16d2d159872fd213cae4b8f371d7ae9c8b027c89" />
    <Meta Name="ms.translationtype" Value="HT" />
    <Meta Name="ms.contentlocale" Value="es-ES" />
    <Meta Name="ms.lasthandoff" Value="11/17/2018" />
    <Meta Name="ms.locfileid" Value="51901843" />
  </Metadata>
  <TypeSignature Language="C#" Value="public class SpeechRecognizer : IDisposable" />
  <TypeSignature Language="ILAsm" Value=".class public auto ansi beforefieldinit SpeechRecognizer extends System.Object implements class System.IDisposable" />
  <TypeSignature Language="DocId" Value="T:System.Speech.Recognition.SpeechRecognizer" />
  <TypeSignature Language="VB.NET" Value="Public Class SpeechRecognizer&#xA;Implements IDisposable" />
  <TypeSignature Language="C++ CLI" Value="public ref class SpeechRecognizer : IDisposable" />
  <TypeSignature Language="F#" Value="type SpeechRecognizer = class&#xA;    interface IDisposable" />
  <AssemblyInfo>
    <AssemblyName>System.Speech</AssemblyName>
    <AssemblyVersion>3.0.0.0</AssemblyVersion>
    <AssemblyVersion>4.0.0.0</AssemblyVersion>
  </AssemblyInfo>
  <Base>
    <BaseTypeName>System.Object</BaseTypeName>
  </Base>
  <Interfaces>
    <Interface>
      <InterfaceName>System.IDisposable</InterfaceName>
    </Interface>
  </Interfaces>
  <Docs>
    <summary>Proporciona acceso al servicio de reconocimiento de voz compartido disponible en el escritorio de Windows.</summary>
    <remarks>
      <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Las aplicaciones usar el reconocedor compartido para tener acceso a reconocimiento de voz de Windows. Use la <xref:System.Speech.Recognition.SpeechRecognizer> objeto va a agregar a la experiencia del usuario de voz de Windows.  
  
 Esta clase proporciona control sobre diversos aspectos del proceso de reconocimiento de voz:  
  
-   Para administrar las gramáticas reconocimiento de voz, use el <xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammar%2A>, <xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync%2A>, <xref:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar%2A>, <xref:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars%2A>, y <xref:System.Speech.Recognition.SpeechRecognizer.Grammars%2A>.  
  
-   Para obtener información acerca de la síntesis de voz en operaciones de reconocimiento, suscribirse a la <xref:System.Speech.Recognition.SpeechRecognizer>del <xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected>, <xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized>, <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected>, y <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized> eventos.  
  
-   Para ver o modificar el número de resultados alternativos que se devuelve el reconocedor, utilice el <xref:System.Speech.Recognition.SpeechRecognizer.MaxAlternates%2A> propiedad. El reconocedor devuelve los resultados del reconocimiento en un <xref:System.Speech.Recognition.RecognitionResult> objeto.  
  
-   Para obtener acceso o supervisar el estado del reconocedor compartido, utilice el <xref:System.Speech.Recognition.SpeechRecognizer.AudioLevel%2A>, <xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A>, <xref:System.Speech.Recognition.SpeechRecognizer.AudioState%2A>, <xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A>, <xref:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition%2A>, <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A>, y <xref:System.Speech.Recognition.SpeechRecognizer.State%2A> propiedades y el <xref:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated>, <xref:System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred>, <xref:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged>, y <xref:System.Speech.Recognition.SpeechRecognizer.StateChanged> eventos.  
  
-   Para sincronizar los cambios realizados en el módulo de reconocimiento, utilice el <xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A> método. El reconocedor compartido usa más de un subproceso para realizar las tareas.  
  
-   Para emular la entrada para el reconocedor compartido, utilice el <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A> y <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> métodos.  
  
 La configuración de reconocimiento de voz de Windows se administra mediante el uso de la **propiedades de voz** cuadro de diálogo en el **Panel de Control**. Esta interfaz se utiliza para seleccionar el motor de reconocimiento de voz de escritorio de forma predeterminada y lenguaje, el dispositivo de entrada de audio y el comportamiento de suspensión del reconocimiento de voz. Si se cambia la configuración de reconocimiento de voz de Windows mientras se está ejecutando la aplicación (por ejemplo, si el reconocimiento de voz está deshabilitado o se cambia el idioma de entrada), el cambio afecta a todos los <xref:System.Speech.Recognition.SpeechRecognizer> objetos.  
  
 Para crear un reconocedor de voz en curso que es independiente del reconocimiento de voz de Windows, use la <xref:System.Speech.Recognition.SpeechRecognitionEngine> clase.  
  
> [!NOTE]
>  Llame siempre a <xref:System.Speech.Recognition.SpeechRecognizer.Dispose%2A> antes de liberar la última referencia para el reconocimiento de voz. En caso contrario, los recursos que utiliza no se liberarán hasta que el recolector de elementos no utilizados llama al objeto reconocedor `Finalize` método.  
  
   
  
## Examples  
 El ejemplo siguiente es parte de una aplicación de consola que carga una gramática de reconocimiento de voz y muestra la entrada emulada asincrónica, los resultados de reconocimiento asociados y los eventos asociados generados por el reconocedor de voz.  Si no se está ejecutando el reconocimiento de voz de Windows, a continuación, inicie esta aplicación también se iniciará el reconocimiento de voz de Windows. Si el reconocimiento de voz de Windows está en el **dormir** estado, a continuación, <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> siempre devuelve null.  
  
```csharp  
using System;  
using System.Speech.Recognition;  
using System.Threading;  
  
namespace SharedRecognizer  
{  
  class Program  
  {  
  
    // Indicate whether the asynchronous emulate recognition  
    // operation has completed.  
    static bool completed;  
  
    static void Main(string[] args)  
    {  
  
      // Initialize an instance of the shared recognizer.  
      using (SpeechRecognizer recognizer = new SpeechRecognizer())  
      {  
  
        // Create and load a sample grammar.  
        Grammar testGrammar =  
          new Grammar(new GrammarBuilder("testing testing"));  
        testGrammar.Name = "Test Grammar";  
        recognizer.LoadGrammar(testGrammar);  
  
        // Attach event handlers for recognition events.  
        recognizer.SpeechRecognized +=  
          new EventHandler<SpeechRecognizedEventArgs>(  
            SpeechRecognizedHandler);  
        recognizer.EmulateRecognizeCompleted +=  
          new EventHandler<EmulateRecognizeCompletedEventArgs>(  
            EmulateRecognizeCompletedHandler);  
  
        completed = false;  
  
        // Start asynchronous emulated recognition.   
        // This matches the grammar and generates a SpeechRecognized event.  
        recognizer.EmulateRecognizeAsync("testing testing");  
  
        // Wait for the asynchronous operation to complete.  
        while (!completed)  
        {  
          Thread.Sleep(333);  
        }  
  
        completed = false;  
  
        // Start asynchronous emulated recognition.  
        // This does not match the grammar or generate a SpeechRecognized event.  
        recognizer.EmulateRecognizeAsync("testing one two three");  
  
        // Wait for the asynchronous operation to complete.  
        while (!completed)  
        {  
          Thread.Sleep(333);  
        }  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    // Handle the SpeechRecognized event.  
    static void SpeechRecognizedHandler(  
      object sender, SpeechRecognizedEventArgs e)  
    {  
      if (e.Result != null)  
      {  
        Console.WriteLine("Recognition result = {0}",  
          e.Result.Text ?? "<no text>");  
      }  
      else  
      {  
        Console.WriteLine("No recognition result");  
      }  
    }  
  
    // Handle the SpeechRecognizeCompleted event.  
    static void EmulateRecognizeCompletedHandler(  
      object sender, EmulateRecognizeCompletedEventArgs e)  
    {  
      if (e.Result == null)  
      {  
        Console.WriteLine("No result generated.");  
      }  
  
      // Indicate the asynchronous operation is complete.  
      completed = true;  
    }  
  }  
}  
  
```  
  
 ]]></format>
    </remarks>
    <altmember cref="T:System.Speech.Recognition.SpeechRecognitionEngine" />
    <altmember cref="T:System.Speech.Recognition.Grammar" />
    <altmember cref="T:System.Speech.Recognition.RecognitionResult" />
  </Docs>
  <Members>
    <Member MemberName=".ctor">
      <MemberSignature Language="C#" Value="public SpeechRecognizer ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig specialname rtspecialname instance void .ctor() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.#ctor" />
      <MemberSignature Language="VB.NET" Value="Public Sub New ()" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; SpeechRecognizer();" />
      <MemberType>Constructor</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Parameters />
      <Docs>
        <summary>Inicializa una nueva instancia de la clase <see cref="T:System.Speech.Recognition.SpeechRecognizer" />.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Cada <xref:System.Speech.Recognition.SpeechRecognizer> objeto mantiene un conjunto independiente de las gramáticas reconocimiento de voz.  
  
   
  
## Examples  
 El ejemplo siguiente es parte de una aplicación de consola que carga una gramática de reconocimiento de voz y muestra la entrada emulada asincrónica, los resultados de reconocimiento asociados y los eventos asociados generados por el reconocedor de voz. Si no se está ejecutando el reconocimiento de voz de Windows, a continuación, inicie esta aplicación también se iniciará el reconocimiento de voz de Windows. Si el reconocimiento de voz de Windows está en el **dormir** estado, a continuación, <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> siempre devuelve null.  
  
```csharp  
using System;  
using System.Speech.Recognition;  
using System.Threading;  
  
namespace SharedRecognizer  
{  
  class Program  
  {  
  
    // Indicate whether the asynchronous emulate recognition  
    // operation has completed.  
    static bool completed;  
  
    static void Main(string[] args)  
    {  
  
      // Initialize an instance of the shared recognizer.  
      using (SpeechRecognizer recognizer = new SpeechRecognizer())  
      {  
  
        // Create and load a sample grammar.  
        Grammar testGrammar =  
          new Grammar(new GrammarBuilder("testing testing"));  
        testGrammar.Name = "Test Grammar";  
        recognizer.LoadGrammar(testGrammar);  
  
        // Attach event handlers for recognition events.  
        recognizer.SpeechRecognized +=  
          new EventHandler<SpeechRecognizedEventArgs>(  
            SpeechRecognizedHandler);  
        recognizer.EmulateRecognizeCompleted +=  
          new EventHandler<EmulateRecognizeCompletedEventArgs>(  
            EmulateRecognizeCompletedHandler);  
  
        completed = false;  
  
        // Start asynchronous emulated recognition.   
        // This matches the grammar and generates a SpeechRecognized event.  
        recognizer.EmulateRecognizeAsync("testing testing");  
  
        // Wait for the asynchronous operation to complete.  
        while (!completed)  
        {  
          Thread.Sleep(333);  
        }  
  
        completed = false;  
  
        // Start asynchronous emulated recognition.  
        // This does not match the grammar or generate a SpeechRecognized event.  
        recognizer.EmulateRecognizeAsync("testing one two three");  
  
        // Wait for the asynchronous operation to complete.  
        while (!completed)  
        {  
          Thread.Sleep(333);  
        }  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    // Handle the SpeechRecognized event.  
    static void SpeechRecognizedHandler(  
      object sender, SpeechRecognizedEventArgs e)  
    {  
      if (e.Result != null)  
      {  
        Console.WriteLine("Recognition result = {0}",  
          e.Result.Text ?? "<no text>");  
      }  
      else  
      {  
        Console.WriteLine("No recognition result");  
      }  
    }  
  
    // Handle the SpeechRecognizeCompleted event.  
    static void EmulateRecognizeCompletedHandler(  
      object sender, EmulateRecognizeCompletedEventArgs e)  
    {  
      if (e.Result == null)  
      {  
        Console.WriteLine("No result generated.");  
      }  
  
      // Indicate the asynchronous operation is complete.  
      completed = true;  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.SpeechRecognitionEngine" />
        <altmember cref="T:System.Speech.Recognition.Grammar" />
      </Docs>
    </Member>
    <Member MemberName="AudioFormat">
      <MemberSignature Language="C#" Value="public System.Speech.AudioFormat.SpeechAudioFormatInfo AudioFormat { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance class System.Speech.AudioFormat.SpeechAudioFormatInfo AudioFormat" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.SpeechRecognizer.AudioFormat" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property AudioFormat As SpeechAudioFormatInfo" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::Speech::AudioFormat::SpeechAudioFormatInfo ^ AudioFormat { System::Speech::AudioFormat::SpeechAudioFormatInfo ^ get(); };" />
      <MemberSignature Language="F#" Value="member this.AudioFormat : System.Speech.AudioFormat.SpeechAudioFormatInfo" Usage="System.Speech.Recognition.SpeechRecognizer.AudioFormat" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.AudioFormat.SpeechAudioFormatInfo</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Obtiene el formato del sonido que es recibido por el reconocedor de voz.</summary>
        <value>El formato de entrada de audio para el módulo de reconocimiento de voz, o <see langword="null" /> si la entrada al reconocedor no está configurada.</value>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="AudioLevel">
      <MemberSignature Language="C#" Value="public int AudioLevel { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance int32 AudioLevel" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.SpeechRecognizer.AudioLevel" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property AudioLevel As Integer" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property int AudioLevel { int get(); };" />
      <MemberSignature Language="F#" Value="member this.AudioLevel : int" Usage="System.Speech.Recognition.SpeechRecognizer.AudioLevel" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Int32</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Obtiene el nivel del sonido que es recibido por el reconocedor de voz.</summary>
        <value>El nivel de audio de la entrada al módulo de reconocimiento de voz, de 0 a 100.</value>
        <remarks>To be added.</remarks>
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated" />
      </Docs>
    </Member>
    <Member MemberName="AudioLevelUpdated">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Recognition.AudioLevelUpdatedEventArgs&gt; AudioLevelUpdated;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Recognition.AudioLevelUpdatedEventArgs&gt; AudioLevelUpdated" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated" />
      <MemberSignature Language="VB.NET" Value="Public Custom Event AudioLevelUpdated As EventHandler(Of AudioLevelUpdatedEventArgs) " />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Recognition::AudioLevelUpdatedEventArgs ^&gt; ^ AudioLevelUpdated;" />
      <MemberSignature Language="F#" Value="member this.AudioLevelUpdated : EventHandler&lt;System.Speech.Recognition.AudioLevelUpdatedEventArgs&gt; " Usage="member this.AudioLevelUpdated : System.EventHandler&lt;System.Speech.Recognition.AudioLevelUpdatedEventArgs&gt; " />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Recognition.AudioLevelUpdatedEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Se produce cuando el reconocedor compartido indica el nivel de su entrada de audio.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 El reconocedor provoca este evento varias veces por segundo. Depende de la frecuencia con la que se genera el evento en el equipo donde se ejecuta la aplicación.  
  
 Para obtener el nivel de audio en el momento del evento, use la <xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs.AudioLevel%2A> propiedad del asociado <xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs>. Para obtener el nivel de audio actual de la entrada al reconocedor, use el reconocedor <xref:System.Speech.Recognition.SpeechRecognizer.AudioLevel%2A> propiedad.  
  
 Cuando se crea un delegado para un `AudioLevelUpdated` eventos, identifica el método que controlará el evento. Para asociar el evento al controlador, se debe agregar una instancia del delegado al evento. Siempre que se produce el evento, se llama a su controlador, a menos que se quite el delegado. Para obtener más información sobre los delegados de controlador de eventos, consulte [eventos y delegados](https://go.microsoft.com/fwlink/?LinkId=162418).  
  
   
  
## Examples  
 En el ejemplo siguiente se agrega un controlador para el `AudioLevelUpdated` eventos a un <xref:System.Speech.Recognition.SpeechRecognizer> objeto. El controlador genera el nuevo nivel de audio en la consola.  
  
```csharp  
private SpeechRecognizer recognizer;  
  
// Initialize the SpeechRecognizer object.   
private void Initialize()  
{  
  recognizer = new SpeechRecognizer();  
  
  // Add an event handler for the AudioLevelUpdated event.  
  recognizer.AudioLevelUpdated +=   
    new EventHandler<AudioLevelUpdatedEventArgs>(recognizer_AudioLevelUpdated);  
  
  // Add other initialization code here.  
  
}  
  
// Write the audio level to the console when the AudioLevelUpdated event is raised.  
void recognizer_AudioLevelUpdated(object sender, AudioLevelUpdatedEventArgs e)  
{  
  Console.WriteLine("The audio level is now: {0}.", e.AudioLevel);  
}  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.AudioLevelUpdatedEventArgs" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.AudioLevel" />
      </Docs>
    </Member>
    <Member MemberName="AudioPosition">
      <MemberSignature Language="C#" Value="public TimeSpan AudioPosition { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance valuetype System.TimeSpan AudioPosition" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property AudioPosition As TimeSpan" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property TimeSpan AudioPosition { TimeSpan get(); };" />
      <MemberSignature Language="F#" Value="member this.AudioPosition : TimeSpan" Usage="System.Speech.Recognition.SpeechRecognizer.AudioPosition" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.TimeSpan</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Obtiene la ubicación actual en la secuencia audio generada por el dispositivo que está proporcionando entradas al módulo de reconocimiento de voz.</summary>
        <value>La ubicación actual del flujo de entrada de audio del módulo de reconocimiento de voz a través de la que ha recibido la entrada.</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 El reconocedor compartido recibe la entrada mientras se está ejecutando el reconocimiento de voz de escritorio.  
  
 El `AudioPosition` propiedad hace referencia a la posición del dispositivo de entrada en su secuencia de audio generado. Por el contrario, el <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A> propiedad hace referencia a la posición del reconocedor en el procesamiento de entrada de audio. Estas posiciones pueden ser diferentes.  Por ejemplo, si el reconocedor ha recibido de entrada para que TI no tiene aún genera un resultado de reconocimiento, a continuación, el valor de la <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A> propiedad es menor que el valor de la <xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A> propiedad.  
  
   
  
## Examples  
 En el ejemplo siguiente, el reconocimiento de voz compartido usa una gramática de dictado para que coincida con la entrada de voz. Un controlador para el <xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected> escribe eventos en la consola la <xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A>, <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A>, y <xref:System.Speech.Recognition.SpeechRecognizer.AudioLevel%2A> cuando el reconocedor de voz detecta la voz en su entrada.  
  
```  
using System;  
using System.Speech.Recognition;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    private static SpeechRecognizer recognizer;  
    public static void Main(string[] args)  
    {  
  
      // Initialize a shared speech recognition engine.  
      recognizer = new SpeechRecognizer();  
  
      // Add handlers for events.  
      recognizer.LoadGrammarCompleted +=   
        new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  
      recognizer.SpeechRecognized +=   
        new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  
      recognizer.StateChanged +=   
        new EventHandler<StateChangedEventArgs>(recognizer_StateChanged);  
      recognizer.SpeechDetected +=   
        new EventHandler<SpeechDetectedEventArgs>(recognizer_SpeechDetected);  
  
      // Create a dictation grammar.  
      Grammar dictation = new DictationGrammar();  
      dictation.Name = "Dictation";  
  
      // Load the grammar object to the recognizer.  
      recognizer.LoadGrammarAsync(dictation);  
  
      // Keep the console window open.  
      Console.ReadLine();  
    }  
  
    // Gather information about detected speech and write it to the console.  
    static void recognizer_SpeechDetected(object sender, SpeechDetectedEventArgs e)  
    {  
      Console.WriteLine();  
      Console.WriteLine("Speech detected:");  
      Console.WriteLine("  Audio level: " + recognizer.AudioLevel);  
      Console.WriteLine("  Audio position: " + recognizer.AudioPosition);  
      Console.WriteLine("  Recognizer audio position: " + recognizer.RecognizerAudioPosition);  
    }  
  
    // Write the text of the recognition result to the console.  
    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  
    {   
      Console.WriteLine("Speech recognized: " + e.Result.Text);  
  
      // Add event handler code here.  
    }  
  
    // Write the name of the loaded grammar to the console.  
    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  
    {  
      Console.WriteLine("Grammar loaded: " + e.Grammar.Name);  
    }  
  
    // Put the shared speech recognizer into "listening" mode.  
    static void recognizer_StateChanged(object sender, StateChangedEventArgs e)  
    {  
      if (e.RecognizerState != RecognizerState.Stopped)  
      {  
        recognizer.EmulateRecognizeAsync("Start listening");  
      }  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition" />
      </Docs>
    </Member>
    <Member MemberName="AudioSignalProblemOccurred">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Recognition.AudioSignalProblemOccurredEventArgs&gt; AudioSignalProblemOccurred;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Recognition.AudioSignalProblemOccurredEventArgs&gt; AudioSignalProblemOccurred" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred" />
      <MemberSignature Language="VB.NET" Value="Public Custom Event AudioSignalProblemOccurred As EventHandler(Of AudioSignalProblemOccurredEventArgs) " />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Recognition::AudioSignalProblemOccurredEventArgs ^&gt; ^ AudioSignalProblemOccurred;" />
      <MemberSignature Language="F#" Value="member this.AudioSignalProblemOccurred : EventHandler&lt;System.Speech.Recognition.AudioSignalProblemOccurredEventArgs&gt; " Usage="member this.AudioSignalProblemOccurred : System.EventHandler&lt;System.Speech.Recognition.AudioSignalProblemOccurredEventArgs&gt; " />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Recognition.AudioSignalProblemOccurredEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Se produce cuando el reconocedor encuentra un problema en la señal audio.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Para obtener el problema, use el <xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs.AudioSignalProblem%2A> propiedad del asociado <xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs>.  
  
 Cuando se crea un delegado para un `AudioSignalProblemOccurred` eventos, identifica el método que controlará el evento. Para asociar el evento al controlador, se debe agregar una instancia del delegado al evento. Siempre que se produce el evento, se llama a su controlador, a menos que se quite el delegado. Para obtener más información sobre los delegados de controlador de eventos, consulte [eventos y delegados](https://go.microsoft.com/fwlink/?LinkId=162418).  
  
   
  
## Examples  
 En el ejemplo siguiente se define un controlador de eventos que recopila información sobre un `AudioSignalProblemOccurred` eventos.  
  
```  
private SpeechRecognizer recognizer;  
  
// Initialize the speech recognition engine.  
private void Initialize()  
{  
  recognizer = new SpeechRecognizer();  
  
  // Add a handler for the AudioSignalProblemOccurred event.  
  recognizer.AudioSignalProblemOccurred +=   
    new EventHandler<AudioSignalProblemOccurredEventArgs>(  
      recognizer_AudioSignalProblemOccurred);  
}  
  
// Gather information when the AudioSignalProblemOccurred event is raised.  
void recognizer_AudioSignalProblemOccurred(object sender, AudioSignalProblemOccurredEventArgs e)  
{  
  StringBuilder details = new StringBuilder();  
  
  details.AppendLine("Audio signal problem information:");  
  details.AppendFormat(  
    " Audio level:               {0}" + Environment.NewLine +  
    " Audio position:            {1}" + Environment.NewLine +  
    " Audio signal problem:      {2}" + Environment.NewLine +  
    " Recognition engine audio position: {3}" + Environment.NewLine,  
    e.AudioLevel, e.AudioPosition,  e.AudioSignalProblem,  
    e.recoEngineAudioPosition);  
  
  // Insert additional event handler code here.  
}  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.AudioSignalProblem" />
        <altmember cref="T:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs" />
      </Docs>
    </Member>
    <Member MemberName="AudioState">
      <MemberSignature Language="C#" Value="public System.Speech.Recognition.AudioState AudioState { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance valuetype System.Speech.Recognition.AudioState AudioState" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.SpeechRecognizer.AudioState" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property AudioState As AudioState" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::Speech::Recognition::AudioState AudioState { System::Speech::Recognition::AudioState get(); };" />
      <MemberSignature Language="F#" Value="member this.AudioState : System.Speech.Recognition.AudioState" Usage="System.Speech.Recognition.SpeechRecognizer.AudioState" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Recognition.AudioState</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Obtiene el estado del sonido que es recibido por el reconocedor de voz.</summary>
        <value>El estado de la entrada de audio en el módulo de reconocimiento de voz.</value>
        <remarks>To be added.</remarks>
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged" />
      </Docs>
    </Member>
    <Member MemberName="AudioStateChanged">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Recognition.AudioStateChangedEventArgs&gt; AudioStateChanged;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Recognition.AudioStateChangedEventArgs&gt; AudioStateChanged" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged" />
      <MemberSignature Language="VB.NET" Value="Public Custom Event AudioStateChanged As EventHandler(Of AudioStateChangedEventArgs) " />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Recognition::AudioStateChangedEventArgs ^&gt; ^ AudioStateChanged;" />
      <MemberSignature Language="F#" Value="member this.AudioStateChanged : EventHandler&lt;System.Speech.Recognition.AudioStateChangedEventArgs&gt; " Usage="member this.AudioStateChanged : System.EventHandler&lt;System.Speech.Recognition.AudioStateChangedEventArgs&gt; " />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Recognition.AudioStateChangedEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Se produce cuando cambia el estado en el sonido que recibe el reconocedor.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Para obtener el estado de audio en el momento del evento, use la <xref:System.Speech.Recognition.AudioStateChangedEventArgs.AudioState%2A> propiedad del asociado <xref:System.Speech.Recognition.AudioStateChangedEventArgs>. Para obtener el estado de la entrada para el reconocimiento de audio actual, use el reconocedor <xref:System.Speech.Recognition.SpeechRecognizer.AudioState%2A> propiedad. Para obtener más información sobre el estado de audio, consulte el <xref:System.Speech.Recognition.AudioState> enumeración.  
  
 Cuando se crea un delegado para un `AudioStateChanged` eventos, identifica el método que controlará el evento. Para asociar el evento al controlador, se debe agregar una instancia del delegado al evento. Siempre que se produce el evento, se llama a su controlador, a menos que se quite el delegado. Para obtener más información sobre los delegados de controlador de eventos, consulte [eventos y delegados](https://go.microsoft.com/fwlink/?LinkId=162418).  
  
   
  
## Examples  
 En el ejemplo siguiente se usa un controlador para el `AudioStateChanged` del nuevo evento para el reconocedor de escritura <xref:System.Speech.Recognition.SpeechRecognizer.AudioState%2A> en la consola cada vez que los cambios mediante un miembro de la <xref:System.Speech.Recognition.AudioState> enumeración.  
  
```  
using System;  
using System.Speech.Recognition;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    private static SpeechRecognizer recognizer;  
    public static void Main(string[] args)  
    {  
  
      // Initialize a shared speech recognition engine.  
      recognizer = new SpeechRecognizer();  
  
        // Create and load a grammar.  
        Grammar dictation = new DictationGrammar();  
        dictation.Name = "Dictation Grammar";  
        recognizer.LoadGrammar(dictation);  
  
        // Attach event handlers.  
        recognizer.AudioStateChanged +=  
          new EventHandler<AudioStateChangedEventArgs>(recognizer_AudioStateChanged);  
        recognizer.SpeechRecognized +=  
          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  
        recognizer.StateChanged +=  
          new EventHandler<StateChangedEventArgs>(recognizer_StateChanged);  
  
        // Keep the console window open.  
        Console.ReadLine();  
      }  
  
    // Handle the AudioStateChanged event.  
    static void recognizer_AudioStateChanged(object sender, AudioStateChangedEventArgs e)  
    {  
      Console.WriteLine("The new audio state is: " + e.AudioState);  
    }  
  
    // Handle the SpeechRecognized event.  
    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  
    {  
      if (e.Result != null && e.Result.Text != null)  
      {  
        Console.WriteLine();  
        Console.WriteLine("  Recognized text =  {0}", e.Result.Text);  
        Console.WriteLine();  
      }  
      else  
      {  
        Console.WriteLine("  Recognized text not available.");  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Done.");  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    // Put the recognizer into Listening mode.  
    static void recognizer_StateChanged(object sender, StateChangedEventArgs e)  
    {  
      if (e.RecognizerState != RecognizerState.Stopped)  
      {  
        Console.WriteLine();  
        recognizer.EmulateRecognizeAsync("Start listening");  
      }  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.AudioState" />
        <altmember cref="T:System.Speech.Recognition.AudioStateChangedEventArgs" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.AudioState" />
      </Docs>
    </Member>
    <MemberGroup MemberName="Dispose">
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Docs>
        <summary>Desecha el objeto <see cref="T:System.Speech.Recognition.SpeechRecognizer" />.</summary>
      </Docs>
    </MemberGroup>
    <Member MemberName="Dispose">
      <MemberSignature Language="C#" Value="public void Dispose ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig newslot virtual instance void Dispose() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.Dispose" />
      <MemberSignature Language="VB.NET" Value="Public Sub Dispose ()" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; virtual void Dispose();" />
      <MemberSignature Language="F#" Value="abstract member Dispose : unit -&gt; unit&#xA;override this.Dispose : unit -&gt; unit" Usage="speechRecognizer.Dispose " />
      <MemberType>Method</MemberType>
      <Implements>
        <InterfaceMember>M:System.IDisposable.Dispose</InterfaceMember>
      </Implements>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary>Desecha el objeto <see cref="T:System.Speech.Recognition.SpeechRecognizer" />.</summary>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <Member MemberName="Dispose">
      <MemberSignature Language="C#" Value="protected virtual void Dispose (bool disposing);" />
      <MemberSignature Language="ILAsm" Value=".method familyhidebysig newslot virtual instance void Dispose(bool disposing) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.Dispose(System.Boolean)" />
      <MemberSignature Language="VB.NET" Value="Protected Overridable Sub Dispose (disposing As Boolean)" />
      <MemberSignature Language="C++ CLI" Value="protected:&#xA; virtual void Dispose(bool disposing);" />
      <MemberSignature Language="F#" Value="abstract member Dispose : bool -&gt; unit&#xA;override this.Dispose : bool -&gt; unit" Usage="speechRecognizer.Dispose disposing" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="disposing" Type="System.Boolean" />
      </Parameters>
      <Docs>
        <param name="disposing">Es <see langword="true" /> para liberar tanto recursos administrados como no administrados; es <see langword="false" /> para liberar únicamente recursos no administrados.</param>
        <summary>Desecha el objeto <see cref="T:System.Speech.Recognition.SpeechRecognizer" /> y libera los recursos utilizados durante la sesión.</summary>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
    <MemberGroup MemberName="EmulateRecognize">
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Docs>
        <summary>Emula la entrada para el reconocimiento de voz compartido, usando el texto en lugar de audio para el reconocimiento de voz sincrónico.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Estos métodos omiten la entrada de audio del sistema. Esto puede resultar útil cuando se está probando o depuración de una aplicación o gramática.  
  
> [!NOTE]
>  Si el reconocimiento de voz de Windows está en el **dormir** de estado, a continuación, estos métodos devuelven `null`.  
  
 El reconocedor compartido se produce la <xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected>, <xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized>, <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected>, y <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized> eventos como si la operación de reconocimiento no se emula. El reconocedor omite las líneas nuevas y el espacio en blanco adicional y trata los signos de puntuación como entrada literal.  
  
> [!NOTE]
>  El <xref:System.Speech.Recognition.RecognitionResult> objeto generado por el reconocedor compartido en respuesta a entrada emulada tiene un valor de `null` para su <xref:System.Speech.Recognition.RecognitionResult.Audio%2A> propiedad.  
  
 Para emular el reconocimiento asincrónico, utilice el <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> método.  
  
 ]]></format>
        </remarks>
      </Docs>
    </MemberGroup>
    <Member MemberName="EmulateRecognize">
      <MemberSignature Language="C#" Value="public System.Speech.Recognition.RecognitionResult EmulateRecognize (string inputText);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance class System.Speech.Recognition.RecognitionResult EmulateRecognize(string inputText) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Function EmulateRecognize (inputText As String) As RecognitionResult" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; System::Speech::Recognition::RecognitionResult ^ EmulateRecognize(System::String ^ inputText);" />
      <MemberSignature Language="F#" Value="member this.EmulateRecognize : string -&gt; System.Speech.Recognition.RecognitionResult" Usage="speechRecognizer.EmulateRecognize inputText" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Recognition.RecognitionResult</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="inputText" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="inputText">La entrada de la operación de reconocimiento.</param>
        <summary>Emula la entrada de una frase al módulo de reconocimiento de voz compartido, usando el texto en lugar de audio para el reconocimiento de voz sincrónico.</summary>
        <returns>Resultado de reconocimiento de la operación de reconocimiento, o <see langword="null" /> si la operación no es correcta o Reconocimiento de voz de Windows está en estado **En suspensión**.</returns>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Los identificadores de las que se incluyen en la Vista y Windows 7 Omitir mayúsculas y minúsculas y ancho de caracteres al aplicar reglas de gramática a la frase de entrada. Para obtener más información acerca de este tipo de comparación, consulte el <xref:System.Globalization.CompareOptions> valores de enumeración <xref:System.Globalization.CompareOptions.OrdinalIgnoreCase> y <xref:System.Globalization.CompareOptions.IgnoreWidth>. Los reconocedores también omite las líneas nuevas y espacio en blanco adicional y tratan los signos de puntuación como entrada literal.  
  
   
  
## Examples  
 El ejemplo siguiente carga una gramática de ejemplo para el reconocedor compartido y emula la entrada al reconocedor. Si no se está ejecutando el reconocimiento de voz de Windows, a continuación, inicie esta aplicación también se iniciará el reconocimiento de voz de Windows. Si el reconocimiento de voz de Windows está en el **dormir** estado, a continuación, <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A> siempre devuelve null.  
  
```csharp  
  
using System;  
using System.Speech.Recognition;  
  
namespace SharedRecognizer  
{  
  class Program  
  {  
  
    static void Main(string[] args)  
    {  
      // Initialize an instance of the shared recognizer.  
      using (SpeechRecognizer recognizer = new SpeechRecognizer())  
      {  
        // Create and load a sample grammar.  
        Grammar testGrammar =  
          new Grammar(new GrammarBuilder("testing testing"));  
        testGrammar.Name = "Test Grammar";  
  
        recognizer.LoadGrammar(testGrammar);  
  
        RecognitionResult result;  
  
        // This EmulateRecognize call matches the grammar and returns a  
        // recognition result.  
        result = recognizer.EmulateRecognize("testing testing");  
        OutputResult(result);  
  
        // This EmulateRecognize call does not match the grammar and   
        // returns null.  
        result = recognizer.EmulateRecognize("testing one two three");  
        OutputResult(result);  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    // Output information about a recognition result to the console.  
    private static void OutputResult(RecognitionResult result)  
    {  
      if (result != null)  
      {  
        Console.WriteLine("Recognition result = {0}",  
          result.Text ?? "<no text>");  
      }  
      else  
      {  
        Console.WriteLine("No recognition result");  
      }  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.RecognitionResult" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String)" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized" />
      </Docs>
    </Member>
    <Member MemberName="EmulateRecognize">
      <MemberSignature Language="C#" Value="public System.Speech.Recognition.RecognitionResult EmulateRecognize (System.Speech.Recognition.RecognizedWordUnit[] wordUnits, System.Globalization.CompareOptions compareOptions);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance class System.Speech.Recognition.RecognitionResult EmulateRecognize(class System.Speech.Recognition.RecognizedWordUnit[] wordUnits, valuetype System.Globalization.CompareOptions compareOptions) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; System::Speech::Recognition::RecognitionResult ^ EmulateRecognize(cli::array &lt;System::Speech::Recognition::RecognizedWordUnit ^&gt; ^ wordUnits, System::Globalization::CompareOptions compareOptions);" />
      <MemberSignature Language="F#" Value="member this.EmulateRecognize : System.Speech.Recognition.RecognizedWordUnit[] * System.Globalization.CompareOptions -&gt; System.Speech.Recognition.RecognitionResult" Usage="speechRecognizer.EmulateRecognize (wordUnits, compareOptions)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Recognition.RecognitionResult</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="wordUnits" Type="System.Speech.Recognition.RecognizedWordUnit[]" />
        <Parameter Name="compareOptions" Type="System.Globalization.CompareOptions" />
      </Parameters>
      <Docs>
        <param name="wordUnits">Matriz de unidades de palabra que contiene la entrada de la operación de reconocimiento.</param>
        <param name="compareOptions">Combinación bit a bit de los valores de enumeración que describen el tipo de comparación que se va a usar para la operación emulada de reconocimiento.</param>
        <summary>Emula la entrada de palabras específicas al módulo de reconocimiento de voz compartido, usando texto en lugar de audio para el reconocimiento de voz sincrónico, y especifica cómo el reconocedor controla la comparación Unicode entre las palabras y las gramáticas reconocimiento de voz cargadas.</summary>
        <returns>Resultado de reconocimiento de la operación de reconocimiento, o <see langword="null" /> si la operación no es correcta o Reconocimiento de voz de Windows está en estado **En suspensión**.</returns>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Este método crea un <xref:System.Speech.Recognition.RecognitionResult> objeto con la información proporcionada en el `wordUnits` parámetro.  
  
 El reconocedor utiliza la `compareOptions` cuando se aplica reglas de gramática a la frase de entrada. Los identificadores de las que se incluyen en la Vista y Windows 7 Omitir mayúsculas y minúsculas si la <xref:System.Globalization.CompareOptions.OrdinalIgnoreCase> o <xref:System.Globalization.CompareOptions.IgnoreCase> valor está presente. Los reconocedores de ignorar siempre el ancho de caracteres y nunca omitir el tipo Kana. Los reconocedores también omite las líneas nuevas y espacio en blanco adicional y trata los signos de puntuación como entrada literal. Para obtener más información sobre el ancho de caracteres y el tipo de Kana, consulte el <xref:System.Globalization.CompareOptions> enumeración.  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.RecognitionResult" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String)" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized" />
      </Docs>
    </Member>
    <Member MemberName="EmulateRecognize">
      <MemberSignature Language="C#" Value="public System.Speech.Recognition.RecognitionResult EmulateRecognize (string inputText, System.Globalization.CompareOptions compareOptions);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance class System.Speech.Recognition.RecognitionResult EmulateRecognize(string inputText, valuetype System.Globalization.CompareOptions compareOptions) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String,System.Globalization.CompareOptions)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; System::Speech::Recognition::RecognitionResult ^ EmulateRecognize(System::String ^ inputText, System::Globalization::CompareOptions compareOptions);" />
      <MemberSignature Language="F#" Value="member this.EmulateRecognize : string * System.Globalization.CompareOptions -&gt; System.Speech.Recognition.RecognitionResult" Usage="speechRecognizer.EmulateRecognize (inputText, compareOptions)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Recognition.RecognitionResult</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="inputText" Type="System.String" />
        <Parameter Name="compareOptions" Type="System.Globalization.CompareOptions" />
      </Parameters>
      <Docs>
        <param name="inputText">La frase de entrada de la operación de reconocimiento.</param>
        <param name="compareOptions">Combinación bit a bit de los valores de enumeración que describen el tipo de comparación que se va a usar para la operación emulada de reconocimiento.</param>
        <summary>Emula la entrada de una frase al módulo de reconocimiento de voz compartido, usando texto en lugar de audio para el reconocimiento de voz sincrónico, y especifica cómo el reconocedor controla la comparación Unicode entre la frase y las gramáticas reconocimiento de voz cargadas.</summary>
        <returns>Resultado de reconocimiento de la operación de reconocimiento, o <see langword="null" /> si la operación no es correcta o Reconocimiento de voz de Windows está en estado **En suspensión**.</returns>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 El reconocedor utiliza la `compareOptions` cuando se aplica reglas de gramática a la frase de entrada. Los identificadores de las que se incluyen en la Vista y Windows 7 Omitir mayúsculas y minúsculas si la <xref:System.Globalization.CompareOptions.OrdinalIgnoreCase> o <xref:System.Globalization.CompareOptions.IgnoreCase> valor está presente. Los reconocedores de ignorar siempre el ancho de caracteres y nunca omitir el tipo Kana. Los reconocedores también omite las líneas nuevas y espacio en blanco adicional y trata los signos de puntuación como entrada literal. Para obtener más información sobre el ancho de caracteres y el tipo de Kana, consulte el <xref:System.Globalization.CompareOptions> enumeración.  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.RecognitionResult" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String)" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized" />
      </Docs>
    </Member>
    <MemberGroup MemberName="EmulateRecognizeAsync">
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Docs>
        <summary>Emula la entrada para el reconocimiento de voz compartido, usando el texto en lugar de audio para el reconocimiento de voz asincrónico.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Estos métodos omiten la entrada de audio del sistema. Esto puede resultar útil cuando se está probando o depuración de una aplicación o gramática.  
  
 El reconocedor compartido se produce la <xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected>, <xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized>, <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected>, y <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized> eventos como si la operación de reconocimiento no se emula. Cuando el reconocedor finaliza la operación de reconocimiento asincrónica, se genera el <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted> eventos. El reconocedor omite las líneas nuevas y el espacio en blanco adicional y trata los signos de puntuación como entrada literal.  
  
> [!NOTE]
>  Si el reconocimiento de voz de Windows está en el **dormir** de estado, a continuación, el reconocedor compartido no procesa la entrada y no genera el <xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected> y eventos relacionados, pero todavía genera el <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted> eventos.  
  
> [!NOTE]
>  El <xref:System.Speech.Recognition.RecognitionResult> objeto generado por el reconocedor compartido en respuesta a entrada emulada tiene un valor de `null` para su <xref:System.Speech.Recognition.RecognitionResult.Audio%2A> propiedad.  
  
 Para emular el reconocimiento de sincrónico, utilice el <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A> método.  
  
 ]]></format>
        </remarks>
      </Docs>
    </MemberGroup>
    <Member MemberName="EmulateRecognizeAsync">
      <MemberSignature Language="C#" Value="public void EmulateRecognizeAsync (string inputText);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void EmulateRecognizeAsync(string inputText) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String)" />
      <MemberSignature Language="VB.NET" Value="Public Sub EmulateRecognizeAsync (inputText As String)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void EmulateRecognizeAsync(System::String ^ inputText);" />
      <MemberSignature Language="F#" Value="member this.EmulateRecognizeAsync : string -&gt; unit" Usage="speechRecognizer.EmulateRecognizeAsync inputText" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="inputText" Type="System.String" />
      </Parameters>
      <Docs>
        <param name="inputText">La entrada de la operación de reconocimiento.</param>
        <summary>Emula la entrada de una frase al módulo de reconocimiento de voz compartido, usando el texto en lugar de audio para el reconocimiento de voz asincrónico.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Los identificadores de las que se incluyen en la Vista y Windows 7 Omitir mayúsculas y minúsculas y ancho de caracteres al aplicar reglas de gramática a la frase de entrada. Para obtener más información acerca de este tipo de comparación, consulte el <xref:System.Globalization.CompareOptions> valores de enumeración <xref:System.Globalization.CompareOptions.OrdinalIgnoreCase> y <xref:System.Globalization.CompareOptions.IgnoreWidth>. Los reconocedores también omite las líneas nuevas y espacio en blanco adicional y tratan los signos de puntuación como entrada literal.  
  
   
  
## Examples  
 El ejemplo siguiente es parte de una aplicación de consola que carga una gramática de reconocimiento de voz y muestra la entrada emulada asincrónica, los resultados de reconocimiento asociados y los eventos asociados generados por el reconocedor de voz. Si no se está ejecutando el reconocimiento de voz de Windows, a continuación, inicie esta aplicación también se iniciará el reconocimiento de voz de Windows. Si el reconocimiento de voz de Windows está en el **dormir** estado, a continuación, <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> siempre devuelve null.  
  
```csharp  
using System;  
using System.Speech.Recognition;  
using System.Threading;  
  
namespace SharedRecognizer  
{  
  class Program  
  {  
    static bool completed;  
  
    static void Main(string[] args)  
    {  
      // Initialize an instance of the shared recognizer.  
      using (SpeechRecognizer recognizer = new SpeechRecognizer())  
      {  
        // Create and load a sample grammar.  
        Grammar testGrammar =  
          new Grammar(new GrammarBuilder("testing testing"));  
        testGrammar.Name = "Test Grammar";  
  
        recognizer.LoadGrammar(testGrammar);  
  
        // Attach event handlers for recognition events.  
        recognizer.SpeechRecognized +=  
          new EventHandler<SpeechRecognizedEventArgs>(  
            SpeechRecognizedHandler);  
        recognizer.EmulateRecognizeCompleted +=  
          new EventHandler<EmulateRecognizeCompletedEventArgs>(  
            EmulateRecognizeCompletedHandler);  
  
        completed = false;  
  
        // This EmulateRecognizeAsync call generates a SpeechRecognized event.  
        recognizer.EmulateRecognizeAsync("testing testing");  
  
        // Wait for the asynchronous operation to complete.  
        while (!completed)  
        {  
          Thread.Sleep(333);  
        }  
  
        completed = false;  
  
        // This EmulateRecognizeAsync call does not match the grammar   
        // or generate a SpeechRecognized event.  
        recognizer.EmulateRecognizeAsync("testing one two three");  
  
        // Wait for the asynchronous operation to complete.  
        while (!completed)  
        {  
          Thread.Sleep(333);  
        }  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    // Handle the SpeechRecognized event.  
    static void SpeechRecognizedHandler(  
      object sender, SpeechRecognizedEventArgs e)  
    {  
      if (e.Result != null)  
      {  
        Console.WriteLine("Recognition result = {0}",  
          e.Result.Text ?? "<no text>");  
      }  
      else  
      {  
        Console.WriteLine("No recognition result");  
      }  
    }  
  
    // Handle the EmulateRecognizeCompleted event.   
    static void EmulateRecognizeCompletedHandler(  
      object sender, EmulateRecognizeCompletedEventArgs e)  
    {  
      if (e.Result == null)  
      {  
        Console.WriteLine("No result generated.");  
      }  
  
      completed = true;  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String)" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized" />
      </Docs>
    </Member>
    <Member MemberName="EmulateRecognizeAsync">
      <MemberSignature Language="C#" Value="public void EmulateRecognizeAsync (System.Speech.Recognition.RecognizedWordUnit[] wordUnits, System.Globalization.CompareOptions compareOptions);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void EmulateRecognizeAsync(class System.Speech.Recognition.RecognizedWordUnit[] wordUnits, valuetype System.Globalization.CompareOptions compareOptions) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void EmulateRecognizeAsync(cli::array &lt;System::Speech::Recognition::RecognizedWordUnit ^&gt; ^ wordUnits, System::Globalization::CompareOptions compareOptions);" />
      <MemberSignature Language="F#" Value="member this.EmulateRecognizeAsync : System.Speech.Recognition.RecognizedWordUnit[] * System.Globalization.CompareOptions -&gt; unit" Usage="speechRecognizer.EmulateRecognizeAsync (wordUnits, compareOptions)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="wordUnits" Type="System.Speech.Recognition.RecognizedWordUnit[]" />
        <Parameter Name="compareOptions" Type="System.Globalization.CompareOptions" />
      </Parameters>
      <Docs>
        <param name="wordUnits">Matriz de unidades de palabra que contiene la entrada de la operación de reconocimiento.</param>
        <param name="compareOptions">Combinación bit a bit de los valores de enumeración que describen el tipo de comparación que se va a usar para la operación emulada de reconocimiento.</param>
        <summary>Emula la entrada de palabras específicas al módulo de reconocimiento de voz compartido, usando texto en lugar de audio para el reconocimiento de voz asincrónico, y especifica cómo el reconocedor controla la comparación Unicode entre las palabras y las gramáticas reconocimiento de voz cargadas.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Este método crea un <xref:System.Speech.Recognition.RecognitionResult> objeto con la información proporcionada en el `wordUnits` parámetro.  
  
 El reconocedor utiliza la `compareOptions` cuando se aplica reglas de gramática a la frase de entrada. Los identificadores de las que se incluyen en la Vista y Windows 7 Omitir mayúsculas y minúsculas si la <xref:System.Globalization.CompareOptions.OrdinalIgnoreCase> o <xref:System.Globalization.CompareOptions.IgnoreCase> valor está presente. Los reconocedores de ignorar siempre el ancho de caracteres y nunca omitir el tipo Kana. Los reconocedores también omite las líneas nuevas y espacio en blanco adicional y trata los signos de puntuación como entrada literal. Para obtener más información sobre el ancho de caracteres y el tipo de Kana, consulte el <xref:System.Globalization.CompareOptions> enumeración.  
  
 ]]></format>
        </remarks>
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String)" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized" />
      </Docs>
    </Member>
    <Member MemberName="EmulateRecognizeAsync">
      <MemberSignature Language="C#" Value="public void EmulateRecognizeAsync (string inputText, System.Globalization.CompareOptions compareOptions);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void EmulateRecognizeAsync(string inputText, valuetype System.Globalization.CompareOptions compareOptions) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void EmulateRecognizeAsync(System::String ^ inputText, System::Globalization::CompareOptions compareOptions);" />
      <MemberSignature Language="F#" Value="member this.EmulateRecognizeAsync : string * System.Globalization.CompareOptions -&gt; unit" Usage="speechRecognizer.EmulateRecognizeAsync (inputText, compareOptions)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="inputText" Type="System.String" />
        <Parameter Name="compareOptions" Type="System.Globalization.CompareOptions" />
      </Parameters>
      <Docs>
        <param name="inputText">La frase de entrada de la operación de reconocimiento.</param>
        <param name="compareOptions">Combinación bit a bit de los valores de enumeración que describen el tipo de comparación que se va a usar para la operación emulada de reconocimiento.</param>
        <summary>Emula la entrada de una frase al módulo de reconocimiento de voz compartido, usando texto en lugar de audio para el reconocimiento de voz asincrónico, y especifica cómo el reconocedor controla la comparación Unicode entre la frase y las gramáticas reconocimiento de voz cargadas.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 El reconocedor utiliza la `compareOptions` cuando se aplica reglas de gramática a la frase de entrada. Los identificadores de las que se incluyen en la Vista y Windows 7 Omitir mayúsculas y minúsculas si la <xref:System.Globalization.CompareOptions.OrdinalIgnoreCase> o <xref:System.Globalization.CompareOptions.IgnoreCase> valor está presente. Los reconocedores de ignorar siempre el ancho de caracteres y nunca omitir el tipo Kana. Los reconocedores también omite las líneas nuevas y espacio en blanco adicional y trata los signos de puntuación como entrada literal. Para obtener más información sobre el ancho de caracteres y el tipo de Kana, consulte el <xref:System.Globalization.CompareOptions> enumeración.  
  
 ]]></format>
        </remarks>
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String)" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized" />
      </Docs>
    </Member>
    <Member MemberName="EmulateRecognizeCompleted">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Recognition.EmulateRecognizeCompletedEventArgs&gt; EmulateRecognizeCompleted;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Recognition.EmulateRecognizeCompletedEventArgs&gt; EmulateRecognizeCompleted" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted" />
      <MemberSignature Language="VB.NET" Value="Public Event EmulateRecognizeCompleted As EventHandler(Of EmulateRecognizeCompletedEventArgs) " />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Recognition::EmulateRecognizeCompletedEventArgs ^&gt; ^ EmulateRecognizeCompleted;" />
      <MemberSignature Language="F#" Value="member this.EmulateRecognizeCompleted : EventHandler&lt;System.Speech.Recognition.EmulateRecognizeCompletedEventArgs&gt; " Usage="member this.EmulateRecognizeCompleted : System.EventHandler&lt;System.Speech.Recognition.EmulateRecognizeCompletedEventArgs&gt; " />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Recognition.EmulateRecognizeCompletedEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Se produce cuando el reconocedor compartido finaliza una operación asincrónica de reconocimiento para una entrada emulada.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Cada <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> método comienza una operación asincrónica de reconocimiento. Reconocedor provoca la `EmulateRecognizeCompleted` evento cuando finaliza la operación asincrónica.  
  
 La operación de reconocimiento asincrónica puede provocar la <xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected>, <xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized>, <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected>, y <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized> eventos. El <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted> eventos son el último evento que provoca el reconocedor para una operación determinada.  
  
 Cuando se crea un delegado para un `EmulateRecognizeCompleted` eventos, identifica el método que controlará el evento. Para asociar el evento al controlador, se debe agregar una instancia del delegado al evento. Siempre que se produce el evento, se llama a su controlador, a menos que se quite el delegado. Para obtener más información sobre los delegados de controlador de eventos, consulte [eventos y delegados](https://go.microsoft.com/fwlink/?LinkId=162418).  
  
   
  
## Examples  
 El ejemplo siguiente es parte de una aplicación de consola que carga una gramática de reconocimiento de voz y muestra la entrada emulada asincrónica, los resultados de reconocimiento asociados y los eventos asociados generados por el reconocedor de voz. Si no se está ejecutando el reconocimiento de voz de Windows, a continuación, inicie esta aplicación también se iniciará el reconocimiento de voz de Windows. Si el reconocimiento de voz de Windows está en el **dormir** , a continuación, el modo <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> siempre devuelve null.  
  
```csharp  
using System;  
using System.Speech.Recognition;  
using System.Threading;  
  
namespace SharedRecognizer  
{  
  class Program  
  {  
    // Indicate whether the asynchronous emulate recognition  
    // operation has completed.  
    static bool completed;  
  
    static void Main(string[] args)  
    {  
  
      // Initialize an instance of the shared recognizer.  
      using (SpeechRecognizer recognizer = new SpeechRecognizer())  
      {  
        // Create and load a sample grammar.  
        Grammar testGrammar =  
          new Grammar(new GrammarBuilder("testing testing"));  
        testGrammar.Name = "Test Grammar";  
        recognizer.LoadGrammar(testGrammar);  
  
        // Attach event handlers for recognition events.  
        recognizer.SpeechRecognized +=   
          new EventHandler<SpeechRecognizedEventArgs>(SpeechRecognizedHandler);  
        recognizer.EmulateRecognizeCompleted +=   
          new EventHandler<EmulateRecognizeCompletedEventArgs>(  
            EmulateRecognizeCompletedHandler);  
  
        completed = false;  
  
        // This EmulateRecognizeAsync call generates a SpeechRecognized event.  
        recognizer.EmulateRecognizeAsync("testing testing");  
  
        // Wait for the asynchronous operation to complete.  
        while (!completed)  
        {  
          Thread.Sleep(333);  
        }  
  
        completed = false;  
  
        // This EmulateRecognizeAsync call does not match the grammar  
        // or generate a SpeechRecognized event.  
        recognizer.EmulateRecognizeAsync("testing one two three");  
  
        // Wait for the asynchronous operation to complete.  
        while (!completed)  
        {  
          Thread.Sleep(333);  
        }  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    // Handle the SpeechRecognized event.  
    static void SpeechRecognizedHandler(  
      object sender, SpeechRecognizedEventArgs e)  
    {  
      if (e.Result != null)  
      {  
        Console.WriteLine("Recognition result = {0}",  
          e.Result.Text ?? "<no text>");  
      }  
      else  
      {  
        Console.WriteLine("No recognition result");  
      }  
    }  
  
    // Handle the EmulateRecognizeCompleted event.  
    static void EmulateRecognizeCompletedHandler(  
      object sender, EmulateRecognizeCompletedEventArgs e)  
    {  
      if (e.Result == null)  
      {  
        Console.WriteLine("No result generated.");  
      }  
  
      // Indicate the asynchronous operation is complete.  
      completed = true;  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.EmulateRecognizeCompletedEventArgs" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String)" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized" />
      </Docs>
    </Member>
    <Member MemberName="Enabled">
      <MemberSignature Language="C#" Value="public bool Enabled { get; set; }" />
      <MemberSignature Language="ILAsm" Value=".property instance bool Enabled" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.SpeechRecognizer.Enabled" />
      <MemberSignature Language="VB.NET" Value="Public Property Enabled As Boolean" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property bool Enabled { bool get(); void set(bool value); };" />
      <MemberSignature Language="F#" Value="member this.Enabled : bool with get, set" Usage="System.Speech.Recognition.SpeechRecognizer.Enabled" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Boolean</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Obtiene o establece un valor que indica si este objeto <see cref="T:System.Speech.Recognition.SpeechRecognizer" /> está listo para procesar voz.</summary>
        <value>
          <see langword="true" /> si este objeto <see cref="T:System.Speech.Recognition.SpeechRecognizer" /> está realizando reconocimiento de voz; si no, <see langword="false" />.</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Los cambios realizados en esta propiedad no afectan a otras instancias de la <xref:System.Speech.Recognition.SpeechRecognizer> clase.  
  
 De forma predeterminada, el valor de la <xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A> propiedad es `true` para una instancia de la instancia recién creada de <xref:System.Speech.Recognition.SpeechRecognizer>. Mientras esté deshabilitado el reconocedor, ninguna de las gramáticas de reconocimiento de voz del reconocedor están disponible para las operaciones de reconocimiento. Configuración del reconocedor <xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A> propiedad no tiene ningún efecto sobre el reconocedor <xref:System.Speech.Recognition.SpeechRecognizer.State%2A> propiedad.  
  
 ]]></format>
        </remarks>
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition" />
      </Docs>
    </Member>
    <Member MemberName="Grammars">
      <MemberSignature Language="C#" Value="public System.Collections.ObjectModel.ReadOnlyCollection&lt;System.Speech.Recognition.Grammar&gt; Grammars { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance class System.Collections.ObjectModel.ReadOnlyCollection`1&lt;class System.Speech.Recognition.Grammar&gt; Grammars" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.SpeechRecognizer.Grammars" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property Grammars As ReadOnlyCollection(Of Grammar)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::Collections::ObjectModel::ReadOnlyCollection&lt;System::Speech::Recognition::Grammar ^&gt; ^ Grammars { System::Collections::ObjectModel::ReadOnlyCollection&lt;System::Speech::Recognition::Grammar ^&gt; ^ get(); };" />
      <MemberSignature Language="F#" Value="member this.Grammars : System.Collections.ObjectModel.ReadOnlyCollection&lt;System.Speech.Recognition.Grammar&gt;" Usage="System.Speech.Recognition.SpeechRecognizer.Grammars" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Collections.ObjectModel.ReadOnlyCollection&lt;System.Speech.Recognition.Grammar&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Obtiene una colección de los objetos <see cref="T:System.Speech.Recognition.Grammar" /> cargados en esta instancia <see cref="T:System.Speech.Recognition.SpeechRecognizer" />.</summary>
        <value>Una colección de los objetos <see cref="T:System.Speech.Recognition.Grammar" /> que la aplicación cargó en la instancia actual del reconocedor compartido.</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Esta propiedad no devuelve ningún voz gramática de reconocimiento cargada por otra aplicación.  
  
   
  
## Examples  
 El siguiente ejemplo envía información a la consola para cada gramática de reconocimiento de voz cargado en el reconocimiento de voz compartido.  
  
```csharp  
  
using System;  
using System.Collections.Generic;  
using System.Speech.Recognition;  
using System.Threading;  
  
namespace SharedRecognizer  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
      using (SpeechRecognizer recognizer = new SpeechRecognizer())  
      {  
        Grammar sampleGrammar = new Grammar(new GrammarBuilder("sample phrase"));  
        sampleGrammar.Name = "Sample Grammar";  
        recognizer.LoadGrammar(sampleGrammar);  
  
        OutputGrammarList(recognizer);  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    private static void OutputGrammarList(SpeechRecognizer recognizer)  
    {  
      List<Grammar> grammars = new List<Grammar>(recognizer.Grammars);  
      if (grammars.Count > 0)  
      {  
        Console.WriteLine("Loaded grammars:");  
        foreach (Grammar g in grammars)  
        {  
          Console.WriteLine("  Grammar: {0}",  
            (g.Name != null) ? g.Name : "<no name>");  
        }  
      }  
      else  
      {  
        Console.WriteLine("No grammars loaded.");  
      }  
    }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.Grammar" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammar(System.Speech.Recognition.Grammar)" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync(System.Speech.Recognition.Grammar)" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar(System.Speech.Recognition.Grammar)" />
      </Docs>
    </Member>
    <Member MemberName="LoadGrammar">
      <MemberSignature Language="C#" Value="public void LoadGrammar (System.Speech.Recognition.Grammar grammar);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void LoadGrammar(class System.Speech.Recognition.Grammar grammar) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammar(System.Speech.Recognition.Grammar)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void LoadGrammar(System::Speech::Recognition::Grammar ^ grammar);" />
      <MemberSignature Language="F#" Value="member this.LoadGrammar : System.Speech.Recognition.Grammar -&gt; unit" Usage="speechRecognizer.LoadGrammar grammar" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="grammar" Type="System.Speech.Recognition.Grammar" />
      </Parameters>
      <Docs>
        <param name="grammar">La gramática de reconocimiento de voz para cargar.</param>
        <summary>Carga una gramática de reconocimiento de voz.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 El reconocedor compartido produce una excepción si ya está cargada, se cargan de forma asincrónica o no ha podido cargar en cualquier módulo de reconocimiento de la gramática de reconocimiento de voz. Si se está ejecutando el reconocedor, las aplicaciones deben usar <xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A> para pausar el motor de reconocimiento de voz antes de cargar, descargar, habilitar o deshabilitar una gramática.  
  
 Para cargar de forma asincrónica una gramática de reconocimiento de voz, utilice el <xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync%2A> método.  
  
   
  
## Examples  
 El ejemplo siguiente es parte de una aplicación de consola que carga una gramática de reconocimiento de voz y muestra la entrada emulada asincrónica, los resultados de reconocimiento asociados y los eventos asociados generados por el reconocedor de voz. Si no se está ejecutando el reconocimiento de voz de Windows, a continuación, inicie esta aplicación también se iniciará el reconocimiento de voz de Windows. Si el reconocimiento de voz de Windows está en el **dormir** estado, a continuación, <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> siempre devuelve null.  
  
```csharp  
using System;  
using System.Speech.Recognition;  
using System.Threading;  
  
namespace SharedRecognizer  
{  
  class Program  
  {  
    // Indicate whether the asynchronous emulate recognition  
    // operation has completed.  
    static bool completed;  
  
    static void Main(string[] args)  
    {  
      // Initialize an instance of the shared recognizer.  
      using (SpeechRecognizer recognizer = new SpeechRecognizer())  
      {  
        // Create and load a sample grammar.  
        Grammar testGrammar =  
          new Grammar(new GrammarBuilder("testing testing"));  
        testGrammar.Name = "Test Grammar";  
  
        recognizer.LoadGrammar(testGrammar);  
  
        // Attach event handlers for recognition events.  
        recognizer.SpeechRecognized +=  
          new EventHandler<SpeechRecognizedEventArgs>(  
            SpeechRecognizedHandler);  
        recognizer.EmulateRecognizeCompleted +=  
          new EventHandler<EmulateRecognizeCompletedEventArgs>(  
            EmulateRecognizeCompletedHandler);  
  
        completed = false;  
  
        // This EmulateRecognizeAsync call generates a SpeechRecognized event.  
        recognizer.EmulateRecognizeAsync("testing testing");  
  
        // Wait for the asynchronous operation to complete.  
        while (!completed)  
        {  
          Thread.Sleep(333);  
        }  
  
        completed = false;  
  
        // This EmulateRecognizeAsync call does not match the grammar   
        // or generate a SpeechRecognized event.  
        recognizer.EmulateRecognizeAsync("testing one two three");  
  
        // Wait for the asynchronous operation to complete.  
        while (!completed)  
        {  
          Thread.Sleep(333);  
        }  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    // Handle the SpeechRecognized event.  
    static void SpeechRecognizedHandler(  
      object sender, SpeechRecognizedEventArgs e)  
    {  
      if (e.Result != null)  
      {  
        Console.WriteLine("Recognition result = {0}",  
          e.Result.Text ?? "<no text>");  
      }  
      else  
      {  
        Console.WriteLine("No recognition result");  
      }  
    }   
  
    // Handle the EmulateRecognizeCompleted event.   
    static void EmulateRecognizeCompletedHandler(  
      object sender, EmulateRecognizeCompletedEventArgs e)  
    {  
      if (e.Result == null)  
      {  
        Console.WriteLine("No result generated.");  
      }  
  
      completed = true;  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync(System.Speech.Recognition.Grammar)" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar(System.Speech.Recognition.Grammar)" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate" />
      </Docs>
    </Member>
    <Member MemberName="LoadGrammarAsync">
      <MemberSignature Language="C#" Value="public void LoadGrammarAsync (System.Speech.Recognition.Grammar grammar);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void LoadGrammarAsync(class System.Speech.Recognition.Grammar grammar) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync(System.Speech.Recognition.Grammar)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void LoadGrammarAsync(System::Speech::Recognition::Grammar ^ grammar);" />
      <MemberSignature Language="F#" Value="member this.LoadGrammarAsync : System.Speech.Recognition.Grammar -&gt; unit" Usage="speechRecognizer.LoadGrammarAsync grammar" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="grammar" Type="System.Speech.Recognition.Grammar" />
      </Parameters>
      <Docs>
        <param name="grammar">La gramática de reconocimiento de voz para cargar.</param>
        <summary>De forma asincrónica carga una gramática de reconocimiento de voz.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Cuando el reconocedor finaliza esta operación asincrónica, se genera un <xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted> eventos. El reconocedor produce una excepción si ya está cargada, se cargan de forma asincrónica o no ha podido cargar en cualquier módulo de reconocimiento de la gramática de reconocimiento de voz. Si se está ejecutando el reconocedor, las aplicaciones deben usar <xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A> para pausar el motor de reconocimiento de voz antes de cargar, descargar, habilitar o deshabilitar una gramática.  
  
 Para cargar de forma sincrónica una gramática de reconocimiento de voz, utilice el <xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammar%2A> método.  
  
 ]]></format>
        </remarks>
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammar(System.Speech.Recognition.Grammar)" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar(System.Speech.Recognition.Grammar)" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted" />
      </Docs>
    </Member>
    <Member MemberName="LoadGrammarCompleted">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Recognition.LoadGrammarCompletedEventArgs&gt; LoadGrammarCompleted;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Recognition.LoadGrammarCompletedEventArgs&gt; LoadGrammarCompleted" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted" />
      <MemberSignature Language="VB.NET" Value="Public Event LoadGrammarCompleted As EventHandler(Of LoadGrammarCompletedEventArgs) " />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Recognition::LoadGrammarCompletedEventArgs ^&gt; ^ LoadGrammarCompleted;" />
      <MemberSignature Language="F#" Value="member this.LoadGrammarCompleted : EventHandler&lt;System.Speech.Recognition.LoadGrammarCompletedEventArgs&gt; " Usage="member this.LoadGrammarCompleted : System.EventHandler&lt;System.Speech.Recognition.LoadGrammarCompletedEventArgs&gt; " />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Recognition.LoadGrammarCompletedEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Se produce cuando el reconocedor finaliza la carga asincrónica de una gramática de reconocimiento de voz.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 El reconocedor <xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync%2A> método inicia una operación asincrónica. Reconocedor provoca la `LoadGrammarCompleted` eventos cuando se complete la operación. Para obtener el <xref:System.Speech.Recognition.Grammar> que carga el módulo de reconocimiento de objetos, utilice el <xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs.Grammar%2A> propiedad del asociado <xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs>. Para obtener actual <xref:System.Speech.Recognition.Grammar> objetos que se haya cargado el reconocedor, usar el reconocedor <xref:System.Speech.Recognition.SpeechRecognizer.Grammars%2A> propiedad.  
  
 Cuando se crea un delegado para un `LoadGrammarCompleted` eventos, identifica el método que controlará el evento. Para asociar el evento al controlador, se debe agregar una instancia del delegado al evento. Siempre que se produce el evento, se llama a su controlador, a menos que se quite el delegado. Para obtener más información sobre los delegados de controlador de eventos, consulte [eventos y delegados](https://go.microsoft.com/fwlink/?LinkId=162418).  
  
   
  
## Examples  
 En el ejemplo siguiente se crea un reconocedor de voz compartido y, a continuación, crea dos tipos de gramáticas para reconocer palabras específicas y para la aceptación dictados libres. El ejemplo carga todas las gramáticas creadas para el reconocimiento de forma asincrónica. Controladores para el reconocedor <xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted> y <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized> eventos escriben en la consola el nombre de la gramática que se usó para realizar el reconocimiento y el texto del resultado de reconocimiento, respectivamente.  
  
```  
using System;  
using System.Speech.Recognition;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    private static SpeechRecognizer recognizer;  
    public static void Main(string[] args)  
    {  
  
      // Initialize a shared speech recognition engine.  
      recognizer = new SpeechRecognizer();  
  
        // Add a handler for the LoadGrammarCompleted event.  
        recognizer.LoadGrammarCompleted +=  
          new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  
  
        // Add a handler for the SpeechRecognized event.  
        recognizer.SpeechRecognized +=  
          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  
  
        // Add a handler for the StateChanged event.  
        recognizer.StateChanged +=  
          new EventHandler<StateChangedEventArgs>(recognizer_StateChanged);  
  
        // Create "yesno" grammar.  
        Choices yesChoices = new Choices(new string[] { "yes", "yup", "yeah}" });  
        SemanticResultValue yesValue =  
            new SemanticResultValue(yesChoices, (bool)true);  
        Choices noChoices = new Choices(new string[] { "no", "nope", "neah" });  
        SemanticResultValue noValue =  
            new SemanticResultValue(noChoices, (bool)false);  
        SemanticResultKey yesNoKey =  
            new SemanticResultKey("yesno", new Choices(new GrammarBuilder[] { yesValue, noValue }));  
        Grammar yesnoGrammar = new Grammar(yesNoKey);  
        yesnoGrammar.Name = "yesNo";  
  
        // Create "done" grammar.  
        Grammar doneGrammar =  
          new Grammar(new Choices(new string[] { "done", "exit", "quit", "stop" }));  
        doneGrammar.Name = "Done";  
  
        // Create dictation grammar.  
        Grammar dictation = new DictationGrammar();  
        dictation.Name = "Dictation";  
  
        // Load grammars to the recognizer.  
        recognizer.LoadGrammarAsync(yesnoGrammar);  
        recognizer.LoadGrammarAsync(doneGrammar);  
        recognizer.LoadGrammarAsync(dictation);  
  
        // Keep the console window open.  
        Console.ReadLine();  
      }  
  
    // Handle the SpeechRecognized event.  
    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  
    {  
      Console.WriteLine("Grammar({0}): {1}", e.Result.Grammar.Name, e.Result.Text);  
  
      // Add event handler code here.  
    }  
  
    // Handle the LoadGrammarCompleted event.   
    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  
    {  
      string grammarName = e.Grammar.Name;  
      bool grammarLoaded = e.Grammar.Loaded;  
  
      if (e.Error != null)  
      {  
        Console.WriteLine("LoadGrammar for {0} failed with a {1}.",  
        grammarName, e.Error.GetType().Name);  
  
        // Add exception handling code here.  
      }  
  
      Console.WriteLine("Grammar {0} {1} loaded.",  
      grammarName, (grammarLoaded) ? "is" : "is not");  
    }  
  
    // Put the shared speech recognizer into "listening" mode.   
    static void recognizer_StateChanged(object sender, StateChangedEventArgs e)  
    {  
      if (e.RecognizerState != RecognizerState.Stopped)  
      {  
        recognizer.EmulateRecognizeAsync("Start listening");  
      }  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.Grammar" />
        <altmember cref="T:System.Speech.Recognition.LoadGrammarCompletedEventArgs" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.Grammars" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync(System.Speech.Recognition.Grammar)" />
      </Docs>
    </Member>
    <Member MemberName="MaxAlternates">
      <MemberSignature Language="C#" Value="public int MaxAlternates { get; set; }" />
      <MemberSignature Language="ILAsm" Value=".property instance int32 MaxAlternates" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.SpeechRecognizer.MaxAlternates" />
      <MemberSignature Language="VB.NET" Value="Public Property MaxAlternates As Integer" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property int MaxAlternates { int get(); void set(int value); };" />
      <MemberSignature Language="F#" Value="member this.MaxAlternates : int with get, set" Usage="System.Speech.Recognition.SpeechRecognizer.MaxAlternates" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Int32</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Obtiene o establece el número máximo de resultados alternativos de reconocimiento que el reconocedor compartido devuelve para cada operación de reconocimiento.</summary>
        <value>El número máximo de resultados alternativos que el módulo de reconocimiento de voz devuelve para cada operación de reconocimiento.</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 El <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A> propiedad de la <xref:System.Speech.Recognition.RecognitionResult> clase contiene la colección de <xref:System.Speech.Recognition.RecognizedPhrase> objetos que representan otros interpretaciones de candidatos de la entrada.  
  
 El valor predeterminado de <xref:System.Speech.Recognition.SpeechRecognizer.MaxAlternates%2A> es 10.  
  
 ]]></format>
        </remarks>
        <altmember cref="P:System.Speech.Recognition.RecognitionResult.Alternates" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized" />
      </Docs>
    </Member>
    <Member MemberName="PauseRecognizerOnRecognition">
      <MemberSignature Language="C#" Value="public bool PauseRecognizerOnRecognition { get; set; }" />
      <MemberSignature Language="ILAsm" Value=".property instance bool PauseRecognizerOnRecognition" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition" />
      <MemberSignature Language="VB.NET" Value="Public Property PauseRecognizerOnRecognition As Boolean" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property bool PauseRecognizerOnRecognition { bool get(); void set(bool value); };" />
      <MemberSignature Language="F#" Value="member this.PauseRecognizerOnRecognition : bool with get, set" Usage="System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Boolean</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Obtiene o establece un valor que indica si se detiene el reconocedor compartido en las operaciones de reconocimiento mientras una aplicación controla un evento <see cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized" />.</summary>
        <value>
          <see langword="true" /> si el reconocedor compartido espera para procesar la entrada mientras cualquier aplicación esté controlando el evento <see cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized" /> ; si no, <see langword="false" />.</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Establezca esta propiedad en `true`, si dentro de la <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> controlador de eventos que la aplicación necesita para cambiar el estado del servicio de reconocimiento de voz o cambiar las gramáticas de reconocimiento de voz cargada o habilitado antes que el servicio de reconocimiento de voz procesos de entrada más.  
  
> [!NOTE]
>  Establecer el <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> propiedad `true` hace que cada <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> controlador de eventos en todas las aplicaciones para bloquear el servicio de reconocimiento de voz de Windows.  
  
 Para sincronizar los cambios realizados en el reconocedor compartido con el estado de la aplicación, utilice el <xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A> método.  
  
 Cuando <xref:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition%2A> es `true`, durante la ejecución de la <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> controlador, el servicio de reconocimiento de voz se detiene y se almacena en búfer nueva entrada de audio como llegan. Una vez el <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> sale de controlador de eventos, el servicio reanuda el reconocimiento de voz reconocimiento y empieza a procesar la información de su búfer de entrada.  
  
 Para habilitar o deshabilitar el servicio de reconocimiento de voz, utilice el <xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A> propiedad.  
  
 ]]></format>
        </remarks>
        <altmember cref="E:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.Enabled" />
      </Docs>
    </Member>
    <Member MemberName="RecognizerAudioPosition">
      <MemberSignature Language="C#" Value="public TimeSpan RecognizerAudioPosition { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance valuetype System.TimeSpan RecognizerAudioPosition" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property RecognizerAudioPosition As TimeSpan" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property TimeSpan RecognizerAudioPosition { TimeSpan get(); };" />
      <MemberSignature Language="F#" Value="member this.RecognizerAudioPosition : TimeSpan" Usage="System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.TimeSpan</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Obtiene la ubicación actual del reconocedor en la entrada de audio que está procesando.</summary>
        <value>La posición del reconocedor en la entrada de audio que está procesando.</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 El `RecognizerAudioPosition` propiedad hace referencia a la posición del reconocedor en el procesamiento de su entrada de audio. Por el contrario, el <xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A> propiedad hace referencia a la posición del dispositivo de entrada en su secuencia de audio generado. Estas posiciones pueden ser diferentes. Por ejemplo, si el reconocedor ha recibido de entrada para que TI no tiene aún genera un resultado de reconocimiento, a continuación, el valor de la <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A> propiedad es menor que el valor de la <xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A> propiedad.  
  
 ]]></format>
        </remarks>
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition" />
      </Docs>
    </Member>
    <Member MemberName="RecognizerInfo">
      <MemberSignature Language="C#" Value="public System.Speech.Recognition.RecognizerInfo RecognizerInfo { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance class System.Speech.Recognition.RecognizerInfo RecognizerInfo" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.SpeechRecognizer.RecognizerInfo" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property RecognizerInfo As RecognizerInfo" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::Speech::Recognition::RecognizerInfo ^ RecognizerInfo { System::Speech::Recognition::RecognizerInfo ^ get(); };" />
      <MemberSignature Language="F#" Value="member this.RecognizerInfo : System.Speech.Recognition.RecognizerInfo" Usage="System.Speech.Recognition.SpeechRecognizer.RecognizerInfo" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Recognition.RecognizerInfo</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Obtiene información sobre el reconocedor de voz compartido.</summary>
        <value>Información sobre el reconocedor de voz compartido.</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Esta propiedad devuelve información sobre el reconocimiento de voz en uso mediante el reconocimiento de voz de Windows.  
  
   
  
## Examples  
 El ejemplo siguiente envía información sobre el reconocedor compartido en la consola.  
  
```csharp  
  
using System;  
using System.Speech.Recognition;  
  
namespace SharedRecognizer  
{  
  class Program  
  {  
    static void Main(string[] args)  
    {  
      using (SpeechRecognizer recognizer = new SpeechRecognizer())  
      {  
        Console.WriteLine("Recognizer information for the shared recognizer:");  
        Console.WriteLine("  Name: {0}", recognizer.RecognizerInfo.Name);  
        Console.WriteLine("  Culture: {0}", recognizer.RecognizerInfo.Culture.ToString());  
        Console.WriteLine("  Description: {0}", recognizer.RecognizerInfo.Description);  
      }  
  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.RecognizerInfo" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.State" />
      </Docs>
    </Member>
    <Member MemberName="RecognizerUpdateReached">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt; RecognizerUpdateReached;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt; RecognizerUpdateReached" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached" />
      <MemberSignature Language="VB.NET" Value="Public Event RecognizerUpdateReached As EventHandler(Of RecognizerUpdateReachedEventArgs) " />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Recognition::RecognizerUpdateReachedEventArgs ^&gt; ^ RecognizerUpdateReached;" />
      <MemberSignature Language="F#" Value="member this.RecognizerUpdateReached : EventHandler&lt;System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt; " Usage="member this.RecognizerUpdateReached : System.EventHandler&lt;System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt; " />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Se produce cuando el reconocedor realiza una pausa para sincronizar el reconocimiento con otras operaciones.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Las aplicaciones deben usar <xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A> para pausar una instancia en ejecución de <xref:System.Speech.Recognition.SpeechRecognizer> antes de modificar su <xref:System.Speech.Recognition.Grammar> objetos. Por ejemplo, mientras el <xref:System.Speech.Recognition.SpeechRecognizer> está en pausa, puede cargar, descargar, habilitar y deshabilitar <xref:System.Speech.Recognition.Grammar> objetos. El <xref:System.Speech.Recognition.SpeechRecognizer> provoca este evento cuando esté listo para aceptar modificaciones.  
  
 Cuando se crea un delegado para un <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached> eventos, identifica el método que controlará el evento. Para asociar el evento al controlador, se debe agregar una instancia del delegado al evento. Siempre que se produce el evento, se llama a su controlador, a menos que se quite el delegado. Para obtener más información sobre los delegados de controlador de eventos, consulte [eventos y delegados](https://go.microsoft.com/fwlink/?LinkId=162418).  
  
   
  
## Examples  
 El ejemplo siguiente muestra una aplicación de consola que carga y descarga <xref:System.Speech.Recognition.Grammar> objetos. La aplicación usa el <xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A> método para solicitar el motor de reconocimiento de voz para hacer una pausa de forma que pueda recibir una actualización. La aplicación, a continuación, carga o descarga un <xref:System.Speech.Recognition.Grammar> objeto.  
  
 En cada actualización, un controlador para <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached> eventos escribe su nombre y su estado cargado actualmente <xref:System.Speech.Recognition.Grammar> objetos en la consola. Como las gramáticas se cargan y descargan, la aplicación reconoce primero los nombres de los animales de granja de servidores, los nombres de los animales de granja de servidores y los nombres de frutas y, luego, solo los nombres de frutas.  
  
```csharp  
using System;  
using System.Speech.Recognition;  
using System.Collections.Generic;  
using System.Threading;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    private static SpeechRecognizer recognizer;  
    public static void Main(string[] args)  
    {  
  
      // Initialize a shared speech recognition engine.  
      recognizer = new SpeechRecognizer();  
  
      // Create the first grammar - Farm.  
      Choices animals = new Choices(new string[] { "cow", "pig", "goat" });  
      GrammarBuilder farm = new GrammarBuilder(animals);  
      Grammar farmAnimals = new Grammar(farm);  
      farmAnimals.Name = "Farm";  
  
      // Create the second grammar - Fruit.  
      Choices fruit = new Choices(new string[] { "apples", "peaches", "oranges" });  
      GrammarBuilder favorite = new GrammarBuilder(fruit);  
      Grammar favoriteFruit = new Grammar(favorite);  
      favoriteFruit.Name = "Fruit";  
  
      // Attach event handlers.  
      recognizer.SpeechRecognized +=  
        new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  
      recognizer.RecognizerUpdateReached +=  
        new EventHandler<RecognizerUpdateReachedEventArgs>(recognizer_RecognizerUpdateReached);  
      recognizer.StateChanged +=   
        new EventHandler<StateChangedEventArgs>(recognizer_StateChanged);  
  
      // Load the Farm grammar.  
      recognizer.LoadGrammar(farmAnimals);  
      Console.WriteLine("Grammar Farm is loaded");  
  
      // Pause to recognize farm animals.  
      Thread.Sleep(7000);  
      Console.WriteLine();  
  
      // Request an update and load the Fruit grammar.  
      recognizer.RequestRecognizerUpdate();  
      recognizer.LoadGrammarAsync(favoriteFruit);  
      Thread.Sleep(5000);  
  
      // Request an update and unload the Farm grammar.  
      recognizer.RequestRecognizerUpdate();  
      recognizer.UnloadGrammar(farmAnimals);  
      Thread.Sleep(5000);  
  
      // Keep the console window open.  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    // Put the shared speech recognizer into "listening" mode.  
    static void recognizer_StateChanged(object sender, StateChangedEventArgs e)  
    {  
      if (e.RecognizerState != RecognizerState.Stopped)  
      {  
        recognizer.EmulateRecognizeAsync("Start listening");  
      }  
    }  
  
    // At the update, get the names and enabled status of the currently loaded grammars.  
    public static void recognizer_RecognizerUpdateReached(  
      object sender, RecognizerUpdateReachedEventArgs e)  
    {  
      Console.WriteLine();  
      Console.WriteLine("Update reached:");  
      Thread.Sleep(1000);  
  
      string qualifier;  
      List<Grammar> grammars = new List<Grammar>(recognizer.Grammars);  
      foreach (Grammar g in grammars)  
      {  
        qualifier = (g.Enabled) ? "enabled" : "disabled";  
        Console.WriteLine("  Grammar {0} is loaded and is {1}.",  
        g.Name, qualifier);  
      }  
    }  
  
    // Write the text of the recognized phrase to the console.  
    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  
    {  
      Console.WriteLine("  Speech recognized: " + e.Result.Text);  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate" />
        <altmember cref="T:System.Speech.Recognition.RecognizerUpdateReachedEventArgs" />
      </Docs>
    </Member>
    <MemberGroup MemberName="RequestRecognizerUpdate">
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Docs>
        <summary>Solicita que el reconocedor compartido pause y actualice su estado.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Utilice este método para sincronizar los cambios realizados en el reconocedor compartido. Por ejemplo, si carga o descarga una gramática de reconocimiento de voz mientras el reconocedor está procesando la entrada, utilice este método y el <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached> eventos para sincronizar el comportamiento de su aplicación con el estado del reconocedor.  
  
 Cuando se llama a este método, el reconocedor pause o finaliza operaciones asincrónicas y genera un <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached> eventos. Un <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached> controlador de eventos, a continuación, puede modificar el estado del reconocedor entre operaciones de reconocimiento.  
  
 Cuando se llama a este método:  
  
-   Si el reconocedor no está procesando la entrada, el reconocedor genera inmediatamente la <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached> eventos.  
  
-   Si el reconocedor procesa la entrada que consta de silencio o ruido de fondo, el reconocedor pause la operación de reconocimiento y genera el <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached> eventos.  
  
-   Si el reconocedor procesa la entrada que no constan de silencio o ruido de fondo, el reconocedor finaliza la operación de reconocimiento y, a continuación, genera el <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached> eventos.  
  
 Mientras que el reconocedor controla la <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached> eventos:  
  
-   El reconocedor no procesa la entrada y el valor de la <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A> propiedad sigue siendo el mismo.  
  
-   El reconocedor continúa para recopilar de entrada y el valor de la <xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A> puede cambiar la propiedad.  
  
 Para cambiar si el reconocedor compartido detiene las operaciones de reconocimiento mientras una aplicación controla un <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized> eventos, use el <xref:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition%2A> propiedad.  
  
   
  
## Examples  
 El ejemplo siguiente muestra una aplicación de consola que carga y descarga <xref:System.Speech.Recognition.Grammar> objetos. La aplicación usa el <xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A> método para solicitar el motor de reconocimiento de voz para hacer una pausa de forma que pueda recibir una actualización. La aplicación, a continuación, carga o descarga un <xref:System.Speech.Recognition.Grammar> objeto.  
  
 En cada actualización, un controlador para <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached> eventos escribe su nombre y su estado cargado actualmente <xref:System.Speech.Recognition.Grammar> objetos en la consola. Como las gramáticas se cargan y descargan, la aplicación reconoce primero los nombres de los animales de granja de servidores, los nombres de los animales de granja de servidores y los nombres de frutas y, luego, solo los nombres de frutas.  
  
```csharp  
  
using System;  
using System.Speech.Recognition;  
using System.Collections.Generic;  
using System.Threading;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    private static SpeechRecognizer recognizer;  
    public static void Main(string[] args)  
    {  
  
      // Initialize an in-process speech recognition engine and configure its input.  
      recognizer = new SpeechRecognizer();  
  
      // Create the first grammar - Farm.  
      Choices animals = new Choices(new string[] { "cow", "pig", "goat" });  
      GrammarBuilder farm = new GrammarBuilder(animals);  
      Grammar farmAnimals = new Grammar(farm);  
      farmAnimals.Name = "Farm";  
  
      // Create the second grammar - Fruit.  
      Choices fruit = new Choices(new string[] { "apples", "peaches", "oranges" });  
      GrammarBuilder favorite = new GrammarBuilder(fruit);  
      Grammar favoriteFruit = new Grammar(favorite);  
      favoriteFruit.Name = "Fruit";  
  
      // Attach event handlers.  
      recognizer.SpeechRecognized +=  
        new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  
      recognizer.RecognizerUpdateReached +=  
        new EventHandler<RecognizerUpdateReachedEventArgs>(recognizer_RecognizerUpdateReached);  
  
      // Check to see if recognizer is loaded, wait if it is not loaded.  
      if (recognizer.State != RecognizerState.Listening)  
      {  
        Thread.Sleep(5000);  
  
        // Put recognizer in listening state.  
        recognizer.EmulateRecognizeAsync("Start listening");  
      }  
  
      // Load the Farm grammar.  
      recognizer.LoadGrammar(farmAnimals);  
      Console.WriteLine("Grammar Farm is loaded");  
  
      // Pause to recognize farm animals.  
      Thread.Sleep(7000);  
      Console.WriteLine();  
  
      // Request an update and load the Fruit grammar.  
      recognizer.RequestRecognizerUpdate();  
      recognizer.LoadGrammarAsync(favoriteFruit);  
      Thread.Sleep(5000);  
  
      // Request an update and unload the Farm grammar.  
      recognizer.RequestRecognizerUpdate();  
      recognizer.UnloadGrammar(farmAnimals);  
      Thread.Sleep(5000);  
  
      // Keep the console window open.  
      Console.WriteLine();  
      Console.WriteLine("Press any key to exit...");  
      Console.ReadKey();  
    }  
  
    public static void recognizer_RecognizerUpdateReached(object sender, RecognizerUpdateReachedEventArgs e)  
    {  
      // At the update, get the names and enabled status of the currently loaded grammars.  
      Console.WriteLine();  
      Console.WriteLine("Update reached:");  
      Thread.Sleep(1000);  
      string qualifier;  
      List<Grammar> grammars = new List<Grammar>(recognizer.Grammars);  
      foreach (Grammar g in grammars)  
      {  
        qualifier = (g.Enabled) ? "enabled" : "disabled";  
        Console.WriteLine("  Grammar {0} is loaded and is {1}.",  
        g.Name, qualifier);  
      }  
    }  
  
    // Write the text of the recognized phrase to the console.  
    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  
    {  
      Console.WriteLine("  Speech recognized: " + e.Result.Text);  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached" />
      </Docs>
    </MemberGroup>
    <Member MemberName="RequestRecognizerUpdate">
      <MemberSignature Language="C#" Value="public void RequestRecognizerUpdate ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void RequestRecognizerUpdate() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate" />
      <MemberSignature Language="VB.NET" Value="Public Sub RequestRecognizerUpdate ()" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void RequestRecognizerUpdate();" />
      <MemberSignature Language="F#" Value="member this.RequestRecognizerUpdate : unit -&gt; unit" Usage="speechRecognizer.RequestRecognizerUpdate " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary>Solicita que el reconocedor compartido pause y actualice su estado.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Cuando el reconocedor genera el <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached> eventos, el <xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A> propiedad de la <xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs> es `null`.  
  
 Para proporcionar un token de usuario, use el <xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A> o <xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A> método. Para especificar un desplazamiento de posición de audio, use el <xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A> método.  
  
 ]]></format>
        </remarks>
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition" />
      </Docs>
    </Member>
    <Member MemberName="RequestRecognizerUpdate">
      <MemberSignature Language="C#" Value="public void RequestRecognizerUpdate (object userToken);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void RequestRecognizerUpdate(object userToken) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(System.Object)" />
      <MemberSignature Language="VB.NET" Value="Public Sub RequestRecognizerUpdate (userToken As Object)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void RequestRecognizerUpdate(System::Object ^ userToken);" />
      <MemberSignature Language="F#" Value="member this.RequestRecognizerUpdate : obj -&gt; unit" Usage="speechRecognizer.RequestRecognizerUpdate userToken" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="userToken" Type="System.Object" />
      </Parameters>
      <Docs>
        <param name="userToken">Información definida por el usuario que contiene información para la operación.</param>
        <summary>Solicita que el reconocedor compartido pause y actualice su estado y proporcione un token de usuario para el evento asociado.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Cuando el reconocedor genera el <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached> eventos, el <xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A> propiedad de la <xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs> contiene el valor de la `userToken` parámetro.  
  
 Para especificar un desplazamiento de posición de audio, use el <xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A> método.  
  
 ]]></format>
        </remarks>
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition" />
      </Docs>
    </Member>
    <Member MemberName="RequestRecognizerUpdate">
      <MemberSignature Language="C#" Value="public void RequestRecognizerUpdate (object userToken, TimeSpan audioPositionAheadToRaiseUpdate);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void RequestRecognizerUpdate(object userToken, valuetype System.TimeSpan audioPositionAheadToRaiseUpdate) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(System.Object,System.TimeSpan)" />
      <MemberSignature Language="VB.NET" Value="Public Sub RequestRecognizerUpdate (userToken As Object, audioPositionAheadToRaiseUpdate As TimeSpan)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void RequestRecognizerUpdate(System::Object ^ userToken, TimeSpan audioPositionAheadToRaiseUpdate);" />
      <MemberSignature Language="F#" Value="member this.RequestRecognizerUpdate : obj * TimeSpan -&gt; unit" Usage="speechRecognizer.RequestRecognizerUpdate (userToken, audioPositionAheadToRaiseUpdate)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="userToken" Type="System.Object" />
        <Parameter Name="audioPositionAheadToRaiseUpdate" Type="System.TimeSpan" />
      </Parameters>
      <Docs>
        <param name="userToken">Información definida por el usuario que contiene información para la operación.</param>
        <param name="audioPositionAheadToRaiseUpdate">El desplazamiento del <see cref="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition" /> actual para retrasar la solicitud.</param>
        <summary>Solicita que el reconocedor compartido pause y actualice su estado y proporcione un desplazamiento y un token de usuario para el evento asociado.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 El reconocedor no inicia la solicitud de actualización del reconocedor hasta que el reconocedor <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A> es igual a la actual <xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A> más el valor de la `audioPositionAheadToRaiseUpdate` parámetro.  
  
 Cuando el reconocedor genera el <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached> eventos, el <xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A> propiedad de la <xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs> contiene el valor de la `userToken` parámetro.  
  
 ]]></format>
        </remarks>
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition" />
      </Docs>
    </Member>
    <Member MemberName="SpeechDetected">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Recognition.SpeechDetectedEventArgs&gt; SpeechDetected;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Recognition.SpeechDetectedEventArgs&gt; SpeechDetected" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected" />
      <MemberSignature Language="VB.NET" Value="Public Event SpeechDetected As EventHandler(Of SpeechDetectedEventArgs) " />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Recognition::SpeechDetectedEventArgs ^&gt; ^ SpeechDetected;" />
      <MemberSignature Language="F#" Value="member this.SpeechDetected : EventHandler&lt;System.Speech.Recognition.SpeechDetectedEventArgs&gt; " Usage="member this.SpeechDetected : System.EventHandler&lt;System.Speech.Recognition.SpeechDetectedEventArgs&gt; " />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Recognition.SpeechDetectedEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Se produce cuando el reconocedor detecta una entrada que puede identificar como voz.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 El reconocedor compartido puede generar este evento en respuesta a la entrada. El <xref:System.Speech.Recognition.SpeechDetectedEventArgs.AudioPosition%2A> propiedad del asociado <xref:System.Speech.Recognition.SpeechDetectedEventArgs> objeto indica la ubicación en la secuencia de entrada que el reconocedor detecta la voz. Para obtener más información, consulte el <xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A> y <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A> propiedades y el <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A> y <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> métodos.  
  
 Cuando se crea un delegado para un <xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected> eventos, identifica el método que controlará el evento. Para asociar el evento al controlador, se debe agregar una instancia del delegado al evento. Siempre que se produce el evento, se llama a su controlador, a menos que se quite el delegado. Para obtener más información sobre los delegados de controlador de eventos, consulte [eventos y delegados](https://go.microsoft.com/fwlink/?LinkId=162418).  
  
   
  
## Examples  
 El ejemplo siguiente es parte de una aplicación de consola para elegir las ciudades de origen y destino de un vuelo. La aplicación reconoce frases como "Quiero Volar de Miami en Chicago".  El ejemplo se usa el <xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected> eventos al informe el <xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A> se detecta la voz de cada hora.  
  
```  
using System;  
using System.Speech.Recognition;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    static void Main(string[] args)  
  
    // Initialize a shared speech recognition engine.  
    {  
      using (SpeechRecognizer recognizer =  
         new SpeechRecognizer())  
      {  
  
        // Create a grammar.  
        Choices cities = new Choices(new string[] {   
          "Los Angeles", "New York", "Chicago", "San Francisco", "Miami", "Dallas" });  
  
        GrammarBuilder gb = new GrammarBuilder();  
        gb.Append("I would like to fly from");  
        gb.Append(cities);  
        gb.Append("to");  
        gb.Append(cities);  
  
        // Create a Grammar object and load it to the recognizer.  
        Grammar g = new Grammar(gb);  
        g.Name = ("City Chooser");  
        recognizer.LoadGrammarAsync(g);  
  
        // Attach event handlers.  
        recognizer.LoadGrammarCompleted +=  
          new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  
        recognizer.SpeechDetected +=   
          new EventHandler<SpeechDetectedEventArgs>(recognizer_SpeechDetected);  
        recognizer.SpeechRecognized +=  
          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  
  
        // Keep the console window open.  
        Console.ReadLine();  
      }  
    }  
  
    // Handle the SpeechDetected event.  
    static void recognizer_SpeechDetected(object sender, SpeechDetectedEventArgs e)  
    {  
      Console.WriteLine("Speech detected at AudioPosition = {0}", e.AudioPosition);  
    }  
  
    // Handle the LoadGrammarCompleted event.  
    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  
    {  
      Console.WriteLine("Grammar loaded: " + e.Grammar.Name);  
    }  
  
    // Handle the SpeechRecognized event.  
    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  
    {  
      Console.WriteLine("Speech recognized: " + e.Result.Text);  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.SpeechDetectedEventArgs" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.AudioPosition" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition" />
      </Docs>
    </Member>
    <Member MemberName="SpeechHypothesized">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Recognition.SpeechHypothesizedEventArgs&gt; SpeechHypothesized;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Recognition.SpeechHypothesizedEventArgs&gt; SpeechHypothesized" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized" />
      <MemberSignature Language="VB.NET" Value="Public Custom Event SpeechHypothesized As EventHandler(Of SpeechHypothesizedEventArgs) " />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Recognition::SpeechHypothesizedEventArgs ^&gt; ^ SpeechHypothesized;" />
      <MemberSignature Language="F#" Value="member this.SpeechHypothesized : EventHandler&lt;System.Speech.Recognition.SpeechHypothesizedEventArgs&gt; " Usage="member this.SpeechHypothesized : System.EventHandler&lt;System.Speech.Recognition.SpeechHypothesizedEventArgs&gt; " />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Recognition.SpeechHypothesizedEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Se produce cuando el reconocedor ha reconocido una palabra o palabras que pueden ser un componente de varias frases completas en una gramática.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 El reconocedor compartido puede generar este evento cuando la entrada es ambigua. Por ejemplo, para una gramática de reconocimiento de voz que admite el reconocimiento del "nuevo de juegos," o "nueva partida", "nueva de juegos," es una entrada no ambigua, y "nuevo juego" es una entrada ambigua.  
  
 Cuando se crea un delegado para un <xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized> eventos, identifica el método que controlará el evento. Para asociar el evento al controlador, se debe agregar una instancia del delegado al evento. Siempre que se produce el evento, se llama a su controlador, a menos que se quite el delegado. Para obtener más información sobre los delegados de controlador de eventos, consulte [eventos y delegados](https://go.microsoft.com/fwlink/?LinkId=162418).  
  
   
  
## Examples  
 El ejemplo siguiente reconoce frases como "Mostrar la lista de intérpretes en la categoría de jazz". El ejemplo se usa el <xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized> eventos para mostrar fragmentos frases incompletas en la consola, tal como se reconocen.  
  
```  
using System;  
using System.Speech.Recognition;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    static void Main(string[] args)  
  
    // Initialize a shared speech recognition engine.  
    {  
      using (SpeechRecognizer recognizer =  
         new SpeechRecognizer())  
      {  
  
        // Create a grammar.  
        //  Create lists of alternative choices.  
        Choices listTypes = new Choices(new string[] { "albums", "artists" });  
        Choices genres = new Choices(new string[] {   
          "blues", "classical", "gospel", "jazz", "rock" });  
  
        //  Create a GrammarBuilder object and assemble the grammar components.  
        GrammarBuilder mediaMenu = new GrammarBuilder("Display the list of");  
        mediaMenu.Append(listTypes);  
        mediaMenu.Append("in the");  
        mediaMenu.Append(genres);  
        mediaMenu.Append("category.");  
  
        //  Build a Grammar object from the GrammarBuilder.  
        Grammar mediaMenuGrammar = new Grammar(mediaMenu);  
        mediaMenuGrammar.Name = "Media Chooser";  
  
        // Attach event handlers.  
        recognizer.LoadGrammarCompleted +=  
          new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  
        recognizer.SpeechRecognized +=  
          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  
        recognizer.SpeechHypothesized +=   
          new EventHandler<SpeechHypothesizedEventArgs>(recognizer_SpeechHypothesized);  
  
        // Load the grammar object to the recognizer.  
        recognizer.LoadGrammarAsync(mediaMenuGrammar);  
  
        // Keep the console window open.  
        Console.ReadLine();  
      }  
    }  
  
    // Handle the SpeechHypothesized event.  
    static void recognizer_SpeechHypothesized(object sender, SpeechHypothesizedEventArgs e)  
    {  
      Console.WriteLine("Speech hypothesized: " + e.Result.Text);  
    }  
  
    // Handle the LoadGrammarCompleted event.  
    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  
    {  
      Console.WriteLine("Grammar loaded: " + e.Grammar.Name);  
    }  
  
    // Handle the SpeechRecognized event.  
    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  
    {  
      Console.WriteLine("Speech recognized: " + e.Result.Text);  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.SpeechHypothesizedEventArgs" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized" />
      </Docs>
    </Member>
    <Member MemberName="SpeechRecognitionRejected">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Recognition.SpeechRecognitionRejectedEventArgs&gt; SpeechRecognitionRejected;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Recognition.SpeechRecognitionRejectedEventArgs&gt; SpeechRecognitionRejected" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected" />
      <MemberSignature Language="VB.NET" Value="Public Event SpeechRecognitionRejected As EventHandler(Of SpeechRecognitionRejectedEventArgs) " />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Recognition::SpeechRecognitionRejectedEventArgs ^&gt; ^ SpeechRecognitionRejected;" />
      <MemberSignature Language="F#" Value="member this.SpeechRecognitionRejected : EventHandler&lt;System.Speech.Recognition.SpeechRecognitionRejectedEventArgs&gt; " Usage="member this.SpeechRecognitionRejected : System.EventHandler&lt;System.Speech.Recognition.SpeechRecognitionRejectedEventArgs&gt; " />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Recognition.SpeechRecognitionRejectedEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Se produce cuando el reconocedor recibe una entrada que no coincide con ninguna de las gramáticas de reconocimiento de voz que ha cargado.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 El reconocedor compartido provoca este evento si determina que entrada no coincide con la confianza suficiente cualquiera de las gramáticas de reconocimiento de voz cargadas. El <xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A> propiedad de la <xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs> contiene el rechazadas <xref:System.Speech.Recognition.RecognitionResult> objeto.  
  
 Umbrales de confianza para el reconocedor compartido, administrado por <xref:System.Speech.Recognition.SpeechRecognizer>, están asociados con un perfil de usuario y almacena en el registro de Windows. Las aplicaciones no deberían escribir cambios en el registro para las propiedades del reconocedor compartido.  
  
 Cuando se crea un delegado para un <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected> eventos, identifica el método que controlará el evento. Para asociar el evento al controlador, se debe agregar una instancia del delegado al evento. Siempre que se produce el evento, se llama a su controlador, a menos que se quite el delegado. Para obtener más información sobre los delegados de controlador de eventos, consulte [eventos y delegados](https://go.microsoft.com/fwlink/?LinkId=162418).  
  
   
  
## Examples  
 El ejemplo siguiente se reconoce frases como "Mostrar la lista de intérpretes de la categoría de jazz" o "Mostrar totalmente confiable álbumes". El ejemplo usa un controlador para el <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected> eventos para mostrar una notificación en la consola cuando el contenido de voz de entrada no coincide con el contenido de la gramática con la confianza suficiente para generar un reconocimiento correcto.  
  
```csharp  
using System;  
using System.Speech.Recognition;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    static void Main(string[] args)  
  
    // Initialize a shared speech recognition engine.  
    {  
      using (SpeechRecognizer recognizer =  
         new SpeechRecognizer())  
      {  
  
        // Create a grammar.  
        //  Create lists of alternative choices.  
        Choices listTypes = new Choices(new string[] { "albums", "artists" });  
        Choices genres = new Choices(new string[] {   
          "blues", "classical", "gospel", "jazz", "rock" });  
  
        //  Create a GrammarBuilder object and assemble the grammar components.  
        GrammarBuilder mediaMenu = new GrammarBuilder("Display");  
        mediaMenu.Append("the list of", 0, 1);  
        mediaMenu.Append(listTypes);  
        mediaMenu.Append("in the", 0, 1);  
        mediaMenu.Append(genres);  
        mediaMenu.Append("category", 0, 1);  
  
        //  Build a Grammar object from the GrammarBuilder.  
        Grammar mediaMenuGrammar = new Grammar(mediaMenu);  
        mediaMenuGrammar.Name = "Media Chooser";  
  
        // Attach event handlers.  
        recognizer.LoadGrammarCompleted +=  
          new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  
        recognizer.SpeechRecognized +=  
          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  
        recognizer.SpeechRecognitionRejected +=   
          new EventHandler<SpeechRecognitionRejectedEventArgs>(recognizer_SpeechRecognitionRejected);  
  
        // Load the grammar object to the recognizer.  
        recognizer.LoadGrammarAsync(mediaMenuGrammar);  
  
        // Keep the console window open.  
        Console.ReadLine();  
      }  
    }  
  
    // Handle the SpeechRecognitionRejected event.  
    static void recognizer_SpeechRecognitionRejected(object sender, SpeechRecognitionRejectedEventArgs e)  
    {  
      Console.WriteLine("Speech input was rejected.");  
    }  
  
    // Handle the LoadGrammarCompleted event.  
    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  
    {  
      Console.WriteLine("Grammar loaded: " + e.Grammar.Name);  
    }  
  
    // Handle the SpeechRecognized event.  
    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  
    {  
      Console.WriteLine("Speech recognized: " + e.Result.Text);  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized" />
      </Docs>
    </Member>
    <Member MemberName="SpeechRecognized">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Recognition.SpeechRecognizedEventArgs&gt; SpeechRecognized;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Recognition.SpeechRecognizedEventArgs&gt; SpeechRecognized" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized" />
      <MemberSignature Language="VB.NET" Value="Public Event SpeechRecognized As EventHandler(Of SpeechRecognizedEventArgs) " />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Recognition::SpeechRecognizedEventArgs ^&gt; ^ SpeechRecognized;" />
      <MemberSignature Language="F#" Value="member this.SpeechRecognized : EventHandler&lt;System.Speech.Recognition.SpeechRecognizedEventArgs&gt; " Usage="member this.SpeechRecognized : System.EventHandler&lt;System.Speech.Recognition.SpeechRecognizedEventArgs&gt; " />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Recognition.SpeechRecognizedEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Se produce cuando el reconocedor recibe una entrada que coincide con una de sus gramáticas de reconocimiento de voz.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Reconocedor provoca la `SpeechRecognized` eventos si se determina con la confianza suficiente que la entrada coincide con una de las gramáticas de reconocimiento de voz cargados y habilitados. El <xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A> propiedad de la <xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs> contiene aceptado <xref:System.Speech.Recognition.RecognitionResult> objeto.  
  
 Umbrales de confianza para el reconocedor compartido, administrado por <xref:System.Speech.Recognition.SpeechRecognizer>, están asociados con un perfil de usuario y almacena en el registro de Windows. Las aplicaciones no deberían escribir cambios en el registro para las propiedades del reconocedor compartido.  
  
 Cuando el reconocedor recibe una entrada que coincide con una gramática, la <xref:System.Speech.Recognition.Grammar> objeto puede elevar el <xref:System.Speech.Recognition.Grammar.SpeechRecognized> eventos. El <xref:System.Speech.Recognition.Grammar> del objeto <xref:System.Speech.Recognition.Grammar.SpeechRecognized> evento se produce antes que el reconocedor de voz <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized> eventos.  
  
 Cuando se crea un delegado para un <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized> eventos, identifica el método que controlará el evento. Para asociar el evento al controlador, se debe agregar una instancia del delegado al evento. Siempre que se produce el evento, se llama a su controlador, a menos que se quite el delegado. Para obtener más información sobre los delegados de controlador de eventos, consulte [eventos y delegados](https://go.microsoft.com/fwlink/?LinkId=162418).  
  
   
  
## Examples  
 El ejemplo siguiente es parte de una aplicación de consola que carga una gramática de reconocimiento de voz y muestra la entrada de voz del reconocedor compartido, los resultados de reconocimiento asociados y los eventos asociados generados por el reconocedor de voz. Si no se está ejecutando el reconocimiento de voz de Windows, a continuación, inicie esta aplicación también se iniciará el reconocimiento de voz de Windows.  
  
 Se habla de entrada, como "Quiero Volar de Chicago a Miami" desencadenará una <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized> eventos. La frase "Volar me de Houston a Chicago" en términos no desencadenará una <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized> eventos.  
  
 El ejemplo usa un controlador para el <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized> reconoce el evento para mostrar correctamente las frases y la semántica que contienen en la consola.  
  
```csharp  
using System;  
using System.Speech.Recognition;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    static void Main(string[] args)  
  
    // Initialize a shared speech recognition engine.  
    {  
      using (SpeechRecognizer recognizer = new SpeechRecognizer())  
      {  
  
        // Create SemanticResultValue objects that contain cities and airport codes.  
        SemanticResultValue chicago = new SemanticResultValue("Chicago", "ORD");  
        SemanticResultValue boston = new SemanticResultValue("Boston", "BOS");  
        SemanticResultValue miami = new SemanticResultValue("Miami", "MIA");  
        SemanticResultValue dallas = new SemanticResultValue("Dallas", "DFW");  
  
        // Create a Choices object and add the SemanticResultValue objects, using  
        // implicit conversion from SemanticResultValue to GrammarBuilder  
        Choices cities = new Choices();  
        cities.Add(new Choices(new GrammarBuilder[] { chicago, boston, miami, dallas }));  
  
        // Build the phrase and add SemanticResultKeys.  
        GrammarBuilder chooseCities = new GrammarBuilder();  
        chooseCities.Append("I want to fly from");  
        chooseCities.Append(new SemanticResultKey("origin", cities));  
        chooseCities.Append("to");  
        chooseCities.Append(new SemanticResultKey("destination", cities));  
  
        // Build a Grammar object from the GrammarBuilder.  
        Grammar bookFlight = new Grammar(chooseCities);  
        bookFlight.Name = "Book Flight";  
  
        // Add a handler for the LoadGrammarCompleted event.  
        recognizer.LoadGrammarCompleted +=  
          new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  
  
        // Add a handler for the SpeechRecognized event.  
        recognizer.SpeechRecognized +=   
          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  
  
        // Load the grammar object to the recognizer.  
        recognizer.LoadGrammarAsync(bookFlight);  
  
        // Keep the console window open.  
        Console.ReadLine();  
      }  
    }  
  
    // Handle the LoadGrammarCompleted event.  
    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  
    {  
      Console.WriteLine("Grammar loaded: " + e.Grammar.Name);  
      Console.WriteLine();  
    }  
  
    // Handle the SpeechRecognized event.  
    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  
    {  
      Console.WriteLine("Speech recognized:  " + e.Result.Text);  
      Console.WriteLine();  
      Console.WriteLine("Semantic results:");  
      Console.WriteLine("  The flight origin is " + e.Result.Semantics["origin"].Value);  
      Console.WriteLine("  The flight destination is " + e.Result.Semantics["destination"].Value);  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.Grammar" />
        <altmember cref="T:System.Speech.Recognition.RecognitionResult" />
        <altmember cref="T:System.Speech.Recognition.SpeechRecognizedEventArgs" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechDetected" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected" />
      </Docs>
    </Member>
    <Member MemberName="State">
      <MemberSignature Language="C#" Value="public System.Speech.Recognition.RecognizerState State { get; }" />
      <MemberSignature Language="ILAsm" Value=".property instance valuetype System.Speech.Recognition.RecognizerState State" />
      <MemberSignature Language="DocId" Value="P:System.Speech.Recognition.SpeechRecognizer.State" />
      <MemberSignature Language="VB.NET" Value="Public ReadOnly Property State As RecognizerState" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; property System::Speech::Recognition::RecognizerState State { System::Speech::Recognition::RecognizerState get(); };" />
      <MemberSignature Language="F#" Value="member this.State : System.Speech.Recognition.RecognizerState" Usage="System.Speech.Recognition.SpeechRecognizer.State" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Recognition.RecognizerState</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Obtiene el estado de un objeto <see cref="T:System.Speech.Recognition.SpeechRecognizer" />.</summary>
        <value>El estado del objeto <see langword="SpeechRecognizer" />.</value>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Esta propiedad de solo lectura indica si el reconocedor compartido residente en Windows está en el `Stopped` o `Listening` estado. Para obtener más información, vea la enumeración <xref:System.Speech.Recognition.RecognizerState>.  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.RecognizerState" />
        <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.StateChanged" />
      </Docs>
    </Member>
    <Member MemberName="StateChanged">
      <MemberSignature Language="C#" Value="public event EventHandler&lt;System.Speech.Recognition.StateChangedEventArgs&gt; StateChanged;" />
      <MemberSignature Language="ILAsm" Value=".event class System.EventHandler`1&lt;class System.Speech.Recognition.StateChangedEventArgs&gt; StateChanged" />
      <MemberSignature Language="DocId" Value="E:System.Speech.Recognition.SpeechRecognizer.StateChanged" />
      <MemberSignature Language="VB.NET" Value="Public Event StateChanged As EventHandler(Of StateChangedEventArgs) " />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; event EventHandler&lt;System::Speech::Recognition::StateChangedEventArgs ^&gt; ^ StateChanged;" />
      <MemberSignature Language="F#" Value="member this.StateChanged : EventHandler&lt;System.Speech.Recognition.StateChangedEventArgs&gt; " Usage="member this.StateChanged : System.EventHandler&lt;System.Speech.Recognition.StateChangedEventArgs&gt; " />
      <MemberType>Event</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.EventHandler&lt;System.Speech.Recognition.StateChangedEventArgs&gt;</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>Se produce cuando cambia el estado actual del motor de reconocimiento de voz con tecnología Windows Desktop Speech.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 El reconocedor compartido provoca este evento cuando cambia el estado de reconocimiento de voz de Windows para el <xref:System.Speech.Recognition.RecognizerState.Listening> o <xref:System.Speech.Recognition.RecognizerState.Stopped> estado.  
  
 Para obtener el estado del reconocedor compartido en el momento del evento, use la <xref:System.Speech.Recognition.StateChangedEventArgs.RecognizerState%2A> propiedad del asociado <xref:System.Speech.Recognition.StateChangedEventArgs>. Para obtener el estado actual del reconocedor compartido, use el reconocedor <xref:System.Speech.Recognition.SpeechRecognizer.State%2A> propiedad.  
  
 Cuando se crea un delegado para un <xref:System.Speech.Recognition.SpeechRecognizer.StateChanged> eventos, identifica el método que controlará el evento. Para asociar el evento al controlador, se debe agregar una instancia del delegado al evento. Siempre que se produce el evento, se llama a su controlador, a menos que se quite el delegado. Para obtener más información sobre los delegados de controlador de eventos, consulte [eventos y delegados](https://go.microsoft.com/fwlink/?LinkId=162418).  
  
   
  
## Examples  
 En el ejemplo siguiente se crea un reconocedor de voz compartido y, a continuación, crea dos tipos de gramáticas para reconocer palabras específicas y para la aceptación dictados libres. El ejemplo carga todas las gramáticas creadas para el reconocimiento de forma asincrónica.  Un controlador para el <xref:System.Speech.Recognition.SpeechRecognizer.StateChanged> evento utiliza el <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> método para colocar el reconocimiento de Windows en modo de "escucha".  
  
```csharp  
using System;  
using System.Speech.Recognition;  
  
namespace SampleRecognition  
{  
  class Program  
  {  
    private static SpeechRecognizer recognizer;  
    public static void Main(string[] args)  
    {  
  
      // Initialize a shared speech recognition engine.  
      recognizer = new SpeechRecognizer();  
  
      // Add a handler for the LoadGrammarCompleted event.  
      recognizer.LoadGrammarCompleted += new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  
  
      // Add a handler for the SpeechRecognized event.  
      recognizer.SpeechRecognized += new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  
  
      // Add a handler for the StateChanged event.  
      recognizer.StateChanged += new EventHandler<StateChangedEventArgs>(recognizer_StateChanged);  
  
      // Create "yesno" grammar.  
      Choices yesChoices = new Choices(new string[] { "yes", "yup", "yah}" });  
      SemanticResultValue yesValue =  
          new SemanticResultValue(yesChoices, (bool)true);  
      Choices noChoices = new Choices(new string[] { "no", "nope", "nah" });  
      SemanticResultValue noValue = new SemanticResultValue(noChoices, (bool)false);  
      SemanticResultKey yesNoKey =  
          new SemanticResultKey("yesno", new Choices(new GrammarBuilder[] { yesValue, noValue }));  
      Grammar yesnoGrammar = new Grammar(yesNoKey);  
      yesnoGrammar.Name = "yesNo";  
  
      // Create "done" grammar.  
      Grammar doneGrammar =  
        new Grammar(new Choices(new string[] { "done", "exit", "quit", "stop" }));  
      doneGrammar.Name = "Done";  
  
      // Create dictation grammar.  
      Grammar dictation = new DictationGrammar();  
      dictation.Name = "Dictation";  
  
      // Load grammars to the recognizer.  
      recognizer.LoadGrammarAsync(yesnoGrammar);  
      recognizer.LoadGrammarAsync(doneGrammar);  
      recognizer.LoadGrammarAsync(dictation);  
  
      // Keep the console window open.  
      Console.ReadLine();  
    }  
  
    // Put the shared speech recognizer into "listening" mode.  
    static void  recognizer_StateChanged(object sender, StateChangedEventArgs e)  
    {  
     if (e.RecognizerState != RecognizerState.Stopped)  
      {  
        recognizer.EmulateRecognizeAsync("Start listening");  
      }  
    }  
  
    // Write the text of the recognized phrase to the console.  
    static void  recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  
    {  
     Console.WriteLine("Grammar({0}): {1}", e.Result.Grammar.Name, e.Result.Text);  
  
      // Add event handler code here.  
    }  
  
    // Handle the LoadGrammarCompleted event.  
    static void  recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  
    {  
     string grammarName = e.Grammar.Name;  
      bool grammarLoaded = e.Grammar.Loaded;  
      if (e.Error != null)  
      {  
        Console.WriteLine("LoadGrammar for {0} failed with a {1}.",  
        grammarName, e.Error.GetType().Name);  
      }  
  
      // Add exception handling code here.  
      Console.WriteLine("Grammar {0} {1} loaded.",  
      grammarName, (grammarLoaded) ? "is" : "is not");  
    }  
  }  
}  
  
```  
  
 ]]></format>
        </remarks>
        <altmember cref="T:System.Speech.Recognition.RecognizerState" />
        <altmember cref="T:System.Speech.Recognition.StateChangedEventArgs" />
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.State" />
      </Docs>
    </Member>
    <Member MemberName="UnloadAllGrammars">
      <MemberSignature Language="C#" Value="public void UnloadAllGrammars ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void UnloadAllGrammars() cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars" />
      <MemberSignature Language="VB.NET" Value="Public Sub UnloadAllGrammars ()" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void UnloadAllGrammars();" />
      <MemberSignature Language="F#" Value="member this.UnloadAllGrammars : unit -&gt; unit" Usage="speechRecognizer.UnloadAllGrammars " />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters />
      <Docs>
        <summary>Descarga todas las gramáticas de reconocimiento de voz del reconocedor compartido.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Si el reconocedor está cargando actualmente una gramática de forma asincrónica, este método espera hasta que se cargue la gramática, antes de descarga todas las gramáticas del reconocedor.  
  
 Para descargar una gramática específica, utilice el <xref:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar%2A> método.  
  
 ]]></format>
        </remarks>
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.Grammars" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammar(System.Speech.Recognition.Grammar)" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync(System.Speech.Recognition.Grammar)" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar(System.Speech.Recognition.Grammar)" />
      </Docs>
    </Member>
    <Member MemberName="UnloadGrammar">
      <MemberSignature Language="C#" Value="public void UnloadGrammar (System.Speech.Recognition.Grammar grammar);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig instance void UnloadGrammar(class System.Speech.Recognition.Grammar grammar) cil managed" />
      <MemberSignature Language="DocId" Value="M:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar(System.Speech.Recognition.Grammar)" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; void UnloadGrammar(System::Speech::Recognition::Grammar ^ grammar);" />
      <MemberSignature Language="F#" Value="member this.UnloadGrammar : System.Speech.Recognition.Grammar -&gt; unit" Usage="speechRecognizer.UnloadGrammar grammar" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Void</ReturnType>
      </ReturnValue>
      <Parameters>
        <Parameter Name="grammar" Type="System.Speech.Recognition.Grammar" />
      </Parameters>
      <Docs>
        <param name="grammar">La gramática para descargar.</param>
        <summary>Descarga una gramática especificada de reconocimiento de voz del reconocedor compartido.</summary>
        <remarks>
          <format type="text/markdown"><![CDATA[  
  
## Remarks  
 Si se está ejecutando el reconocedor, las aplicaciones deben usar <xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A> para pausar el motor de reconocimiento de voz antes de cargar, descargar, habilitar o deshabilitar una gramática. Para descargar todas las gramáticas, utilice el <xref:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars%2A> método.  
  
 ]]></format>
        </remarks>
        <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.Grammars" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammar(System.Speech.Recognition.Grammar)" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync(System.Speech.Recognition.Grammar)" />
        <altmember cref="M:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars" />
      </Docs>
    </Member>
  </Members>
</Type>