<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" version="1.2" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" original="ns-System.Speech.Recognition.xml" source-language="en-US" target-language="es-ES">
    <header>
      <tool tool-id="mdxliff" tool-name="mdxliff" tool-version="1.0-efd8310" tool-company="Microsoft" />
      <xliffext:skl_file_name xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">5a83ea4b-dd12-480b-bfc8-267272ef1864be08311c812e33ac449fae40c2d2494af9dc7fe5.skl</xliffext:skl_file_name>
      <xliffext:version xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">1.2</xliffext:version>
      <xliffext:ms.openlocfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">be08311c812e33ac449fae40c2d2494af9dc7fe5</xliffext:ms.openlocfilehash>
      <xliffext:ms.sourcegitcommit xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">df6cf590aa3087f6c7c202712eee781c6a3c8f96</xliffext:ms.sourcegitcommit>
      <xliffext:ms.lasthandoff xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">05/10/2018</xliffext:ms.lasthandoff>
    </header>
    <body>
      <group id="content" extype="content">
        <trans-unit id="101" translate="yes" xml:space="preserve">
          <source>The <ph id="ph1">&lt;see cref="N:System.Speech.Recognition" /&gt;</ph> namespace contains Windows Desktop Speech technology types for implementing speech recognition.</source>
          <target state="translated">El espacio de nombres <ph id="ph1">&lt;see cref="N:System.Speech.Recognition" /&gt;</ph> contiene los tipos de la tecnología Windows Desktop Speech para la implementación de reconocimiento de voz.</target>       </trans-unit>
        <trans-unit id="102" translate="yes" xml:space="preserve" extradata="MT">
          <source>The Windows Desktop Speech Technology software offers a basic speech recognition infrastructure that digitizes acoustical signals, and recovers words and speech elements from audio input.</source>
          <target state="translated">El software de la tecnología de voz de escritorio de Windows ofrece una infraestructura de reconocimiento de voz básica que digitaliza acústica señales y se recupera palabras y los elementos de voz de entrada de audio.</target>       </trans-unit>
        <trans-unit id="103" translate="yes" xml:space="preserve" extradata="MT">
          <source>Applications use the <ph id="ph1">&lt;xref:System.Speech.Recognition&gt;</ph> namespace to access and extend this basic speech recognition technology by defining algorithms for identifying and acting on specific phrases or word patterns, and by managing the runtime behavior of this speech infrastructure.</source>
          <target state="translated">Las aplicaciones utilizan la <ph id="ph1">&lt;xref:System.Speech.Recognition&gt;</ph> espacio de nombres para tener acceso a y extender esta tecnología de reconocimiento de voz básico mediante la definición de algoritmos para identificar y actúa en frases específicas o patrones de word y debido a que administra el comportamiento en tiempo de ejecución de esta infraestructura de voz.</target>       </trans-unit>
        <trans-unit id="104" translate="yes" xml:space="preserve" extradata="MT">
          <source><bpt id="p1">**</bpt>Create Grammars<ept id="p1">**</ept></source>
          <target state="translated"><bpt id="p1">**</bpt>Crear las gramáticas<ept id="p1">**</ept></target>       </trans-unit>
        <trans-unit id="105" translate="yes" xml:space="preserve" extradata="MT">
          <source>You create grammars, which consist of a set of rules or constraints, to define words and phrases that your application will recognize as meaningful input.</source>
          <target state="translated">Cree las gramáticas, que constan de un conjunto de reglas o las restricciones, para definir las palabras y frases que reconoce la aplicación como entrada significativo.</target>       </trans-unit>
        <trans-unit id="106" translate="yes" xml:space="preserve" extradata="MT">
          <source>Using a constructor for the <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> class, you can create a grammar object at runtime from <ph id="ph2">&lt;xref:System.Speech.Recognition.GrammarBuilder&gt;</ph> or <ph id="ph3">&lt;xref:System.Speech.Recognition.SrgsGrammar.SrgsDocument&gt;</ph> instances, or from a file, a string, or a stream that contains a definition of a grammar.</source>
          <target state="translated">Utilizar un constructor para la <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> (clase), puede crear un objeto de gramática en tiempo de ejecución de <ph id="ph2">&lt;xref:System.Speech.Recognition.GrammarBuilder&gt;</ph> o <ph id="ph3">&lt;xref:System.Speech.Recognition.SrgsGrammar.SrgsDocument&gt;</ph> instancias, o desde un archivo, una cadena o una secuencia que contiene una definición de una gramática.</target>       </trans-unit>
        <trans-unit id="107" translate="yes" xml:space="preserve" extradata="MT">
          <source>Using the <ph id="ph1">&lt;xref:System.Speech.Recognition.GrammarBuilder&gt;</ph> and <ph id="ph2">&lt;xref:System.Speech.Recognition.Choices&gt;</ph> classes, you can programmatically create grammars of low to medium complexity that can be used to perform recognition for many common scenarios.</source>
          <target state="translated">Mediante el <ph id="ph1">&lt;xref:System.Speech.Recognition.GrammarBuilder&gt;</ph> y <ph id="ph2">&lt;xref:System.Speech.Recognition.Choices&gt;</ph> clases, puede crear mediante programación las gramáticas de baja a media complejidad que puede usarse para realizar el reconocimiento de muchos escenarios comunes.</target>       </trans-unit>
        <trans-unit id="108" translate="yes" xml:space="preserve" extradata="MT">
          <source>To create grammars programmatically that conform to the <bpt id="p1">[</bpt>Speech Recognition Grammar Specification 1.0 (SRGS)<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=201761)</ept> and take advantage of the authoring flexibility of SRGS, use the types of the <ph id="ph1">&lt;xref:System.Speech.Recognition.SrgsGrammar&gt;</ph> namespace.</source>
          <target state="translated">Para crear las gramáticas mediante programación que se ajustan a la <bpt id="p1">[</bpt>reconocimiento de voz de gramática especificación 1.0 (SRGS)<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=201761)</ept> y aprovechar las ventajas de la flexibilidad de creación de SRGS, use los tipos de la <ph id="ph1">&lt;xref:System.Speech.Recognition.SrgsGrammar&gt;</ph> espacio de nombres.</target>       </trans-unit>
        <trans-unit id="109" translate="yes" xml:space="preserve" extradata="MT">
          <source>You can also create XML-format SRGS grammars using any text editor and use the result to create <ph id="ph1">&lt;xref:System.Speech.Recognition.GrammarBuilder&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SrgsGrammar.SrgsDocument&gt;</ph> , or <ph id="ph3">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objects.</source>
          <target state="translated">También puede crear con cualquier texto de las gramáticas de formato XML SRGS editor y usar el resultado para crear <ph id="ph1">&lt;xref:System.Speech.Recognition.GrammarBuilder&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SrgsGrammar.SrgsDocument&gt;</ph> , o <ph id="ph3">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objetos.</target>       </trans-unit>
        <trans-unit id="110" translate="yes" xml:space="preserve" extradata="MT">
          <source>In addition, the <ph id="ph1">&lt;xref:System.Speech.Recognition.DictationGrammar&gt;</ph> class provides a special-case grammar to support a conventional dictation model.</source>
          <target state="translated">Además, la <ph id="ph1">&lt;xref:System.Speech.Recognition.DictationGrammar&gt;</ph> clase proporciona una gramática de casos especiales para admitir un modelo de dictado convencional.</target>       </trans-unit>
        <trans-unit id="111" translate="yes" xml:space="preserve" extradata="MT">
          <source>See <bpt id="p1">[</bpt>Create Grammars<ept id="p1">](http://msdn.microsoft.com/library/dbea278c-21a5-4816-aee7-5fd88ef993dd)</ept> in the <bpt id="p2">[</bpt>System Speech Programming Guide for .NET Framework 4.0<ept id="p2">](http://msdn.microsoft.com/library/610116c7-3817-40ff-857b-5d41e8511043)</ept> for more information and examples.</source>
          <target state="translated">Vea <bpt id="p1">[</bpt>crear gramáticas<ept id="p1">](http://msdn.microsoft.com/library/dbea278c-21a5-4816-aee7-5fd88ef993dd)</ept> en el <bpt id="p2">[</bpt>Guía de programación de la voz del sistema de .NET Framework 4.0<ept id="p2">](http://msdn.microsoft.com/library/610116c7-3817-40ff-857b-5d41e8511043)</ept> para obtener más información y ejemplos.</target>       </trans-unit>
        <trans-unit id="112" translate="yes" xml:space="preserve" extradata="MT">
          <source><bpt id="p1">**</bpt>Manage Speech Recognition Engines<ept id="p1">**</ept></source>
          <target state="translated"><bpt id="p1">**</bpt>Administrar los motores de reconocimiento de voz<ept id="p1">**</ept></target>       </trans-unit>
        <trans-unit id="113" translate="yes" xml:space="preserve" extradata="MT">
          <source>Instances of <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> and <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> supplied with <ph id="ph3">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objects provide the primary access to the speech recognition engines of the Windows Desktop Speech Technology.</source>
          <target state="translated">Instancias de <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> y <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> suministrados con <ph id="ph3">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objetos proporcionan el acceso principal para los motores de reconocimiento de voz de la tecnología de voz de escritorio de Windows.</target>       </trans-unit>
        <trans-unit id="114" translate="yes" xml:space="preserve" extradata="MT">
          <source>You can use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> class to create client applications that use the speech recognition technology provided by Windows, which you can configure through the <bpt id="p1">**</bpt>Control Panel<ept id="p1">**</ept>.</source>
          <target state="translated">Puede usar el <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> clase para crear aplicaciones cliente que utilizan la tecnología de reconocimiento de voz proporcionada por Windows, que se puede configurar a través del <bpt id="p1">**</bpt>el Panel de Control<ept id="p1">**</ept>.</target>       </trans-unit>
        <trans-unit id="115" translate="yes" xml:space="preserve" extradata="MT">
          <source>Such applications accept input through a computer's default audio input mechanism.</source>
          <target state="translated">Dichas aplicaciones aceptan la entrada a través del mecanismo de la entrada de audio de la predeterminada del equipo.</target>       </trans-unit>
        <trans-unit id="116" translate="yes" xml:space="preserve" extradata="MT">
          <source>For more control over the configuration and type of recognition engine, build an application using <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph>, which runs in-process.</source>
          <target state="translated">Para tener más control sobre la configuración y el tipo de motor de reconocimiento, compilar una aplicación usando <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph>, que se ejecuta en proceso.</target>       </trans-unit>
        <trans-unit id="117" translate="yes" xml:space="preserve" extradata="MT">
          <source>Using the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> class, you can also dynamically select audio input from devices, files, or streams.</source>
          <target state="translated">Mediante el <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> (clase), puede seleccionar también dinámicamente de dispositivos, archivos o secuencias de entrada de audio.</target>       </trans-unit>
        <trans-unit id="118" translate="yes" xml:space="preserve" extradata="MT">
          <source>See <bpt id="p1">[</bpt>Initialize and Manage a Speech Recognition Engine<ept id="p1">](http://msdn.microsoft.com/library/6eed5b59-1258-4013-8a4c-a1ddabd93ae4)</ept> in the <bpt id="p2">[</bpt>System Speech Programming Guide for .NET Framework 4.0<ept id="p2">](http://msdn.microsoft.com/library/610116c7-3817-40ff-857b-5d41e8511043)</ept> for more information.</source>
          <target state="translated">Vea <bpt id="p1">[</bpt>inicializar y administrar un motor de reconocimiento de voz<ept id="p1">](http://msdn.microsoft.com/library/6eed5b59-1258-4013-8a4c-a1ddabd93ae4)</ept> en el <bpt id="p2">[</bpt>Guía de programación de la voz del sistema de .NET Framework 4.0<ept id="p2">](http://msdn.microsoft.com/library/610116c7-3817-40ff-857b-5d41e8511043)</ept> para obtener más información.</target>       </trans-unit>
        <trans-unit id="119" translate="yes" xml:space="preserve" extradata="MT">
          <source><bpt id="p1">**</bpt>Respond to Events<ept id="p1">**</ept></source>
          <target state="translated"><bpt id="p1">**</bpt>Responder a eventos<ept id="p1">**</ept></target>       </trans-unit>
        <trans-unit id="120" translate="yes" xml:space="preserve" extradata="MT">
          <source><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> and <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> objects generate events in response to audio input to the speech recognition engine.</source>
          <target state="translated"><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> y <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> objetos generan eventos en respuesta a la entrada de audio para el motor de reconocimiento de voz.</target>       </trans-unit>
        <trans-unit id="121" translate="yes" xml:space="preserve" extradata="MT">
          <source>The <ph id="ph1">`AudioLevelUpdated`</ph>, <ph id="ph2">`AudioSignalProblemOccurred`</ph>, <ph id="ph3">`AudioStateChanged`</ph> events are raised in response to changes in the incoming signal.</source>
          <target state="translated">El <ph id="ph1">`AudioLevelUpdated`</ph>, <ph id="ph2">`AudioSignalProblemOccurred`</ph>, <ph id="ph3">`AudioStateChanged`</ph> se generan eventos en respuesta a los cambios en la señal de entrada.</target>       </trans-unit>
        <trans-unit id="122" translate="yes" xml:space="preserve" extradata="MT">
          <source>The <ph id="ph1">`SpeechDetected`</ph> event is raised when the speech recognition engine identifies incoming audio as speech.</source>
          <target state="translated">El <ph id="ph1">`SpeechDetected`</ph> evento se desencadena cuando el motor de reconocimiento de voz identifica el audio de entrada como voz.</target>       </trans-unit>
        <trans-unit id="123" translate="yes" xml:space="preserve" extradata="MT">
          <source>The speech recognition engine raises the <ph id="ph1">`SpeechRecognized`</ph> event when it matches speech input to one of its loaded grammars, and raises the <ph id="ph2">`SpeechRecognitionRejected`</ph> when speech input does not match any of its loaded grammars.</source>
          <target state="translated">El motor de reconocimiento de voz genera el <ph id="ph1">`SpeechRecognized`</ph> evento cuando coincide con la entrada de voz a una de las gramáticas de sus carga y genera el <ph id="ph2">`SpeechRecognitionRejected`</ph> cuando la entrada de voz no coincide con ninguno de sus gramáticas cargadas.</target>       </trans-unit>
        <trans-unit id="124" translate="yes" xml:space="preserve" extradata="MT">
          <source>Other types of events include the <ph id="ph1">`LoadGrammarCompleted`</ph> event which a speech recognition engine raises when it has loaded a grammar.</source>
          <target state="translated">Otros tipos de eventos se incluyen los <ph id="ph1">`LoadGrammarCompleted`</ph> eventos que un motor de reconocimiento de voz que se desencadena cuando se cargue una gramática.</target>       </trans-unit>
        <trans-unit id="125" translate="yes" xml:space="preserve" extradata="MT">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.StateChanged&gt;</ph> is exclusive to the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> class, which raises the event when the state of Windows Speech Recognition changes.</source>
          <target state="translated">El <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.StateChanged&gt;</ph> es exclusivo de la <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> (clase), que genera el evento cuando cambia el estado de reconocimiento de voz de Windows.</target>       </trans-unit>
        <trans-unit id="126" translate="yes" xml:space="preserve" extradata="MT">
          <source>You can register to be notified for events that the speech recognition engine raises and create handlers using the <ph id="ph1">`EventsArgs`</ph> classes associated with each of these events to program your application's behavior when an event is raised.</source>
          <target state="translated">Se puede registrar para recibir una notificación de eventos que genera el motor de reconocimiento de voz y crear controladores mediante el <ph id="ph1">`EventsArgs`</ph> las clases asociadas con cada uno de estos eventos para programar el comportamiento de la aplicación cuando se produce un evento.</target>       </trans-unit>
        <trans-unit id="127" translate="yes" xml:space="preserve" extradata="MT">
          <source>See <bpt id="p1">[</bpt>Using Speech Recognition Events<ept id="p1">](http://msdn.microsoft.com/library/01c598ca-2e0e-4e89-b303-cd1cef9e8482)</ept> in the <bpt id="p2">[</bpt>System Speech Programming Guide for .NET Framework 4.0<ept id="p2">](http://msdn.microsoft.com/library/610116c7-3817-40ff-857b-5d41e8511043)</ept> for more information.</source>
          <target state="translated">Vea <bpt id="p1">[</bpt>mediante eventos de reconocimiento de voz<ept id="p1">](http://msdn.microsoft.com/library/01c598ca-2e0e-4e89-b303-cd1cef9e8482)</ept> en el <bpt id="p2">[</bpt>Guía de programación de la voz del sistema de .NET Framework 4.0<ept id="p2">](http://msdn.microsoft.com/library/610116c7-3817-40ff-857b-5d41e8511043)</ept> para obtener más información.</target>       </trans-unit>
      </group>
    </body>
  </file>
</xliff>